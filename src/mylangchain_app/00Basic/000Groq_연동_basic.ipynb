{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_tXXwE4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "#load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: 당신은 개발자입니다.\n",
      "Human: 파이썬은 무엇인가요? 자세하게 설명해주세요\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000197F4AA9D60> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000197F4ED61E0> root_client=<openai.OpenAI object at 0x00000197F4AAA930> root_async_client=<openai.AsyncOpenAI object at 0x00000197F4AB8860> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "응답: 파이썬(Python)은 1991년 네덜란드의 개발자 귀도 반 로섬(Guido van Rossum)이 발표한 고급 프로그래밍 언어입니다. 이름은 그가 좋아하는 코미디 그룹 ‘Monty Python’에서 유래했습니다. “ batteries included(배터리 포함) ”라는 철학 아래 풍부한 표준 라이브러리를 기본으로 제공하며, 간결하고 읽기 쉬운 문법으로 생산성을 극대화하는 것을 목표로 설계됐습니다.\n",
      "\n",
      "1. 언어적 특성\n",
      "1) 인터프리터 언어(Interpreted)  \n",
      "   소스코드를 한 줄씩 해석해 즉시 실행합니다. 별도의 컴파일 과정 없이 빠르게 테스트할 수 있으며, REPL(Read-Eval-Print Loop) 환경(예: IDLE, IPython, Jupyter)을 통해 실험적 코딩이 쉽습니다.\n",
      "\n",
      "2) 동적 타이핑(Dynamically Typed)  \n",
      "   변수에 값을 할당할 때 자료형이 자동으로 결정됩니다. 개발 속도는 빨라지지만, 실행 중 타입 에러가 발생할 수 있어 단위 테스트나 타입 힌트(PEP 484)를 활용한 정적 분석 도구(mypy, pyright)를 병행합니다.\n",
      "\n",
      "3) 강타입(Strongly Typed)  \n",
      "   자동 형 변환이 극단적으로 제한돼 의도하지 않은 버그를 줄여줍니다. 예: \"3\" + 3 → TypeError 발생.\n",
      "\n",
      "4) 객체 지향·절차 지향·함수 지향 모두 지원(멀티패러다임)  \n",
      "   클래스 기반 OOP, 순차적 절차 코딩, 고차 함수·람다·컴프리헨션 등 함수형 스타일을 자유롭게 혼용 가능합니다.\n",
      "\n",
      "5) 자동 메모리 관리(GC)  \n",
      "   참조 카운팅과 순환 참조 탐지를 통한 가비지 컬렉션으로 메모리 누수 걱정을 줄입니다.\n",
      "\n",
      "6) 풍부한 데이터 구조  \n",
      "   리스트(list), 튜플(tuple), 딕셔너리(dict), 집합(set), 제너레이터(generator) 등 고성능 컨테이너를 기본 탑재합니다.\n",
      "\n",
      "7) GIL(Global Interpreter Lock)  \n",
      "   CPython(공식 구현체)은 스레드당 하나의 바이트코드 실행권만 허용해 멀티스레드 CPU 바운드 성능이 제한적입니다. I/O 바운드 작업이나 멀티프로세싱, C/C++ 확장, PyPy, Jython, IronPython, GraalPython 등 대체 인터프리터를 통해 우회 가능합니다.\n",
      "\n",
      "2. 문법적 특징\n",
      "- 들여쓰기(Indentation)로 블록 구분 → 중괄호나 begin/end 키워드 없이 깔끔한 코드\n",
      "- 간결한 표현식  \n",
      "  리스트 컴프리헨션: `[x**2 for x in range(10) if x%2==0]`  \n",
      "  다중 대입: `a, b = b, a+b`\n",
      "- 시퀀스 언패킹: `first, *middle, last = items`\n",
      "- with 문을 통한 컨텍스트 관리자: 자원 해결 보장\n",
      "- 데코레이터·클로저·제너레이터: AOP, 코루틴, 지연 평가 구현 용이\n",
      "- 타입 힌트(3.5~) + 데이터클래스(3.7) + 매치문(3.10) 등 최신 문법이 지속 추가됨\n",
      "\n",
      "3. 표준 라이브러리와 생태계\n",
      "- “Batteries included” : sys, os, datetime, re, json, csv, sqlite3, tkinter, asyncio, threading, multiprocessing, pathlib, urllib, http.server, unittest, logging …\n",
      "- 외부 패키지 관리자 pip → PyPI(파이썬 패키지 색인)에 40만 개 이상 등록\n",
      "- 가상환경(venv, conda, poetry, pipenv)으로 의존성 충돌 방지\n",
      "- 주요 서드파티 라이브러리  \n",
      "  과학: NumPy, SciPy, Matplotlib, pandas, SymPy  \n",
      "  머신러닝: scikit-learn, TensorFlow, PyTorch, JAX  \n",
      "  웹: Django, Flask, FastAPI, Tornado, Streamlit  \n",
      "  자동화: Selenium, BeautifulSoup, Scrapy, PyAutoGUI  \n",
      "  게임: Pygame, Panda3D, Arcade  \n",
      "  모바일/임베디드: Kivy, BeeWare, MicroPython, CircuitPython  \n",
      "  데스크톱: PyQt, PySide, Tkinter, wxPython, DearPyGui  \n",
      "- 기업·공공 기관이 직접 라이브러리·API를 파이썬으로 먼저 제공하는 사례 증가\n",
      "\n",
      "4. 성능과 확장성\n",
      "- 순수 Python은 C/C++ 대비 느릴 수 있지만, NumPy의 내부 벡터화, Cython, Numba JIT, PyPy JIT, C/C++ 또는 Rust 확장 모듈로 속도 극복 가능\n",
      "- 멀티코어 활용 시 멀티프로세싱, concurrent.futures, asyncio(단일 스레드 비동기 I/O) 사용\n",
      "- 대규모 시스템도 YouTube, Instagram, Dropbox, Netflix, Reddit, Pinterest 등이 채택\n",
      "\n",
      "5. 교육·연구·업무 자동화\n",
      "- 문법이 단순해 입문자에게 최적(전 세계 초·중·고, 대학 기초 프로그래밍 1위)\n",
      "- 주피터 노트북 + pandas + Matplotlib 조합으로 데이터 정제·시각화·분석이 한 번에\n",
      "- 업무 자동화(Office 파일, PDF, 이메일, GUI 매크로), 봇 제작, 금융·트레이딩 백테스트, IoT·Raspberry Pi\n",
      "\n",
      "6. 버전 역사\n",
      "- Python 2.x(2000) → 2020년 공식 지원 종료\n",
      "- Python 3.x(2008~) : 문자열 유니코드 기본, print문 → 함수, iterator 개선, 비동기 문법 등 대대적 변화\n",
      "- 현재(2024) 최신 안정 버전: 3.12, 3.13 알파 개발 중\n",
      "- 2→3 마이그레이션 도구(2to3, six, future), 호환 레이어 제공\n",
      "\n",
      "7. 개발 환경\n",
      "- 공식 인터프리터 CPython 외 PyPy(속도), Stackless(마이크로스레드), Jython(JVM), IronPython(.NET)\n",
      "- 통합개발환경: PyCharm, VS Code, Spyder, Thonny, Jupyter Lab, Google Colab\n",
      "- 형상관리·CI/CD: GitHub Actions, tox, pytest, pre-commit, black, ruff, flake8, mypy, bandit(보안)\n",
      "\n",
      "8. 라이선스\n",
      "- Python 소프트웨어 재단 라이선스(PSF) → BSD-호환. 상업적 이용·재배포·수정 자유.\n",
      "\n",
      "9. 활용 분야(요약)\n",
      "- 웹·API 서버, 머신러닝·딥러닝, 데이터 엔지니어링·분석, 데브옵스·자동화 스크립트, 사이버 보안·해킹 툴, 게임, 블록체인, 양자 컴퓨팅 SDK, 로보틱스, 자동차·우주·바이오·화학 시뮬레이션 등\n",
      "\n",
      "10. 한계 및 주의\n",
      "- GIL로 인한 멀티스레드 CPU 바운드 한계\n",
      "- 모바일 네이티브(Android/iOS) 앱은 지원 약세 → Kivy, BeeWare, Briefcase 등으로 해결 시도\n",
      "- 런타임 오버헤드가 큰 임베디드 환경에서는 MicroPython/CircuitPython 활용\n",
      "- 동적 타이핑으로 인한 런타임 에러 가능성 → 타입 힌트, 테스트 커버리지 강화\n",
      "\n",
      "요약하자면, 파이썬은 “읽기 쉽고, 쓰기 쉽고, 강력한 생태계를 기본 탑재한 고급 범용 언어”로, 초보자부터 전문가까지 짧은 코드로 큰 결과를 만들어낼 수 있는 대표적 도구입니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D80BFAB4D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D80BFBD8E0>, root_client=<openai.OpenAI object at 0x000001D80BA955B0>, root_async_client=<openai.AsyncOpenAI object at 0x000001D80BFAB530>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"지구의 자전주기는 얼마인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "지구의 자전주기는 24시간입니다. 이를 하루라고 부릅니다.\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
