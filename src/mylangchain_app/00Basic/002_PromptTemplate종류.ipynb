{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 대규모 텍스트 데이터를 사용해 **자기지도 학습**(self‑supervised learning) 방식으로 사전 '\n",
      " '학습됩니다. 이 과정에서 모델은 문맥을 예측하는 목표를 가지고, 주어진 단어 시퀀스의 다음 단어를 맞추도록 신경망 가중치를 조정합니다. '\n",
      " '이후에는 특정 작업에 맞게 **미세조정**(fine‑tuning)하거나 인간 피드백을 활용한 강화학습(RLHF)으로 성능을 향상시킵니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.'\n",
      "('**ChatGPT 모델의 학습 원리 (3문장)**  \\n'\n",
      " '1. 대규모 텍스트 데이터셋을 이용해 Transformer 기반의 신경망을 사전 학습(pre‑training)하여, 다음에 올 단어를 '\n",
      " '예측하도록 학습합니다.  \\n'\n",
      " '2. 사전 학습 단계에서 얻은 일반 언어 이해 능력을 바탕으로, 특정 작업에 맞게 소량의 라벨 데이터나 인간 피드백을 활용해 미세 '\n",
      " '조정(fine‑tuning)합니다.  \\n'\n",
      " '3. 인간의 선호도를 반영한 강화학습(RLHF) 과정을 거쳐, 보다 안전하고 유용한 응답을 생성하도록 최적화합니다.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT 모델의 주요 장점  \\n'\n",
      " '- **다양한 주제에 대한 폭넓은 지식**: 방대한 텍스트 코퍼스를 학습해 일반 상식, 전문 분야, 문화·언어 등 다양한 영역을 '\n",
      " '커버합니다.  \\n'\n",
      " '- **자연스러운 대화 흐름**: 문맥을 장기적으로 유지하면서 일관된 톤과 논리로 답변을 생성해 인간과 유사한 대화 경험을 '\n",
      " '제공합니다.  \\n'\n",
      " '- **빠른 적응성과 확장성**: 미세 조정이나 프롬프트 설계만으로도 새로운 업무, 언어, 스타일 등에 빠르게 적용할 수 있어 다양한 '\n",
      " '산업·서비스에 활용하기 쉽습니다.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT와 비슷한 AI 모델 (한국어 명칭)  \\n'\n",
      " '- **라마 (LLaMA)** – 메타에서 개발한 대규모 언어 모델  \\n'\n",
      " '- **알파코드 (AlphaCode)** – 코드 생성에 특화된 DeepMind 모델  \\n'\n",
      " '- **코히어런스 (Cohere)** – 자연어 처리용 대형 언어 모델  \\n'\n",
      " '- **파인튜닝된 GPT‑NeoX** – EleutherAI가 공개한 오픈소스 GPT 계열 모델  \\n'\n",
      " '- **버터플라이 (BLOOM)** – 다국어 지원을 목표로 한 대규모 오픈소스 모델  \\n'\n",
      " '- **카이로스 (KAIROS)** – 한국어에 특화된 대형 언어 모델(예: 카카오·네이버 등에서 개발)  \\n'\n",
      " '\\n'\n",
      " '이 모델들은 모두 Transformer 구조를 기반으로 대규모 텍스트 데이터를 학습하고, 다양한 언어 생성·이해 작업에 활용됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"한국어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"한국어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'claude 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.']\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('GPT-4는 대규모 텍스트 데이터를 활용해 토큰 단위의 다음 단어를 예측하도록 학습되는 자기 회귀 언어 모델입니다. 학습 과정에서는 '\n",
      " '트랜스포머 아키텍처의 다층 어텐션 메커니즘을 사용해 문맥을 장기적으로 이해하고, 손실 함수를 최소화하도록 파라미터를 최적화합니다. 이렇게 '\n",
      " '축적된 패턴과 지식을 바탕으로 입력에 따라 자연스러운 문장을 생성합니다.')\n",
      "<class 'str'> Gemma 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Gemma 모델은 대규모 텍스트 코퍼스를 사용해 **자기지도학습(self‑supervised learning)** 방식으로 사전 '\n",
      " '학습됩니다.  \\n'\n",
      " '입력 문장의 일부 토큰을 마스킹하거나 다음 토큰을 예측하도록 하여, 모델이 문맥을 이해하고 언어 패턴을 학습하도록 유도합니다.  \\n'\n",
      " '이후 **지도학습(supervised fine‑tuning)** 단계에서 특정 작업(예: 질문‑답변, 요약 등)에 맞는 라벨이 있는 '\n",
      " '데이터셋을 사용해 파라미터를 조정합니다.  \\n'\n",
      " '마지막으로 **RLHF(인간 피드백을 활용한 강화학습)**를 적용해 인간 평가자의 선호에 맞는 출력을 생성하도록 모델을 미세 조정합니다.')\n",
      "<class 'str'> Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Gemini 모델은 대규모 텍스트와 멀티모달 데이터를 사전학습(Pre‑training)하여 언어와 이미지 등 다양한 입력 형식을 '\n",
      " '이해하도록 훈련됩니다.  \\n'\n",
      " '그 후, 인간 피드백을 활용한 강화학습(RLHF) 단계에서 모델의 답변 품질과 안전성을 개선합니다.  \\n'\n",
      " '학습 과정에서는 트랜스포머 아키텍처를 기반으로 셀프‑어텐션 메커니즘을 사용해 문맥 정보를 효율적으로 통합합니다.  \\n'\n",
      " '마지막으로, 도메인‑특화 데이터와 지속적인 업데이트를 통해 최신 지식과 특수 작업 수행 능력을 지속적으로 향상시킵니다.')\n",
      "<class 'str'> claude 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('Claude 모델은 대규모 텍스트 데이터셋을 이용해 자기지도학습(self‑supervised learning) 방식으로 사전 '\n",
      " '학습(pre‑training)됩니다.  \\n'\n",
      " '그 후, 인간 피드백을 활용한 강화학습(RLHF, Reinforcement Learning from Human Feedback) 단계에서 '\n",
      " '질문‑답변, 요약 등 다양한 작업에 맞춰 모델의 출력을 조정합니다.  \\n'\n",
      " '이 두 단계가 결합돼 언어 이해와 생성 능력을 동시에 갖춘 대화형 AI가 완성됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 4},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"claude\", \"count\": 3}\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 딥러닝이란?  \n",
      "\n",
      "딥러닝(Deep Learning)은 **인공신경망(Artificial Neural Network, ANN)**을 기반으로 한 머신러닝(Machine Learning) 방법 중 하나로, **다층 구조(multi‑layer)와 대규모 데이터**를 활용해 복잡한 패턴을 자동으로 학습하는 기술입니다. “딥(Deep)”이라는 말은 **신경망의 은닉층(hidden layer)이 많아 깊이가 깊다는 의미**이며, 이 깊은 구조가 이미지, 음성, 자연어 등 다양한 비정형 데이터를 고성능으로 처리할 수 있게 해 줍니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. 기본 개념\n",
      "\n",
      "| 용어 | 설명 |\n",
      "|------|------|\n",
      "| **인공신경망 (Neural Network)** | 인간 뇌의 뉴런을 모방한 수학적 모델. 입력 → 가중치·편향 → 활성화 함수 → 출력 의 흐름을 갖는다. |\n",
      "| **층 (Layer)** | 입력층, 은닉층, 출력층으로 구분. 은닉층이 많을수록 “깊은” 네트워크가 된다. |\n",
      "| **가중치 (Weight) / 편향 (Bias)** | 학습 과정에서 조정되는 파라미터. 입력값에 곱해져 출력에 영향을 준다. |\n",
      "| **활성화 함수 (Activation Function)** | 비선형성을 부여해 복잡한 함수 근사 가능하게 함. 대표: ReLU, Sigmoid, Tanh, Softmax 등. |\n",
      "| **전방전파 (Forward Propagation)** | 입력이 네트워크를 통과하면서 출력이 계산되는 과정. |\n",
      "| **역전파 (Backpropagation)** | 출력과 정답 사이의 오차를 역으로 전파해 가중치를 업데이트하는 학습 알고리즘. |\n",
      "| **손실 함수 (Loss Function)** | 모델 출력과 실제 정답 사이의 차이를 수치화. 예: MSE, Cross‑Entropy 등. |\n",
      "| **옵티마이저 (Optimizer)** | 손실을 최소화하도록 가중치를 조정하는 방법. 예: SGD, Adam, RMSprop 등. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 왜 “깊은” 네트워크가 중요한가?\n",
      "\n",
      "1. **표현 학습 (Representation Learning)**  \n",
      "   - 얕은(한두 층) 네트워크는 원시 입력을 그대로 사용하거나 간단한 변환만 가능하지만, 깊은 네트워크는 **계층적으로 특징을 추출**합니다.  \n",
      "   - 예) 이미지 → 가장 낮은 층: 에지(edge) 검출 → 중간 층: 텍스처, 패턴 → 높은 층: 객체 형태.\n",
      "\n",
      "2. **비선형성의 조합**  \n",
      "   - 여러 비선형 활성화 함수를 겹쳐 쓰면, **복잡한 비선형 함수**를 근사할 수 있어 전통적인 선형 모델보다 훨씬 강력합니다.\n",
      "\n",
      "3. **파라미터 공유와 지역 연결**  \n",
      "   - CNN(Convolutional Neural Network) 같은 구조는 **필터(가중치)를 공유**해 파라미터 수를 크게 줄이면서도 공간적 특징을 잘 포착합니다.\n",
      "\n",
      "4. **대규모 데이터와 연산 자원의 활용**  \n",
      "   - 현대 GPU·TPU와 같은 병렬 연산 장치를 이용해 수억~수십억 개 파라미터를 효율적으로 학습할 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 주요 딥러닝 모델군\n",
      "\n",
      "| 모델 | 특징 | 주된 활용 분야 |\n",
      "|------|------|----------------|\n",
      "| **CNN (Convolutional Neural Network)** | 2‑D/3‑D 컨볼루션, 풀링, 채널을 이용해 공간적 패턴을 학습 | 이미지·영상 인식, 객체 탐지, 의료 영상 |\n",
      "| **RNN (Recurrent Neural Network)** | 순환 연결을 통해 시계열·시퀀스 정보를 기억 | 음성 인식, 언어 모델, 시계열 예측 |\n",
      "| **LSTM / GRU** | 장기 의존성 문제 해결 (게이트 메커니즘) | 번역, 텍스트 생성, 주가 예측 |\n",
      "| **Transformer** | self‑attention 기반, 병렬 처리에 강함 | 자연어 처리(NLP), 이미지‑텍스트 멀티모달, 코드 생성 |\n",
      "| **GAN (Generative Adversarial Network)** | 생성자와 판별자의 경쟁을 통해 고품질 합성 데이터 생성 | 이미지·동영상 생성, 스타일 변환, 데이터 증강 |\n",
      "| **Autoencoder / Variational Autoencoder (VAE)** | 입력을 압축·복원해 잠재 표현 학습 | 차원 축소, 이상 탐지, 이미지 복원 |\n",
      "| **Graph Neural Network (GNN)** | 그래프 구조 데이터를 직접 처리 | 소셜 네트워크 분석, 화학 분자 예측, 추천 시스템 |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 딥러닝 학습 흐름 (일반적인 파이프라인)\n",
      "\n",
      "1. **데이터 수집·전처리**  \n",
      "   - 라벨링, 정규화(0~1, -1~1), 데이터 증강(이미지 회전·크롭·색상 변형 등)  \n",
      "2. **모델 설계**  \n",
      "   - 층 종류·수, 활성화 함수, 손실 함수, 옵티마이저 선택  \n",
      "3. **학습 (Training)**  \n",
      "   - **배치 학습**(mini‑batch) → 전방전파 → 손실 계산 → 역전파 → 가중치 업데이트  \n",
      "   - **에포크(Epoch)**: 전체 데이터셋을 한 번 순회  \n",
      "   - **학습률(Learning Rate) 스케줄링**: 초기 큰 값 → 점진적 감소 등  \n",
      "4. **검증·튜닝**  \n",
      "   - 검증 데이터로 과적합(overfitting) 여부 확인, 하이퍼파라미터 조정  \n",
      "   - 정규화 기법: Dropout, L2 정규화, 배치 정규화(BatchNorm) 등  \n",
      "5. **테스트·배포**  \n",
      "   - 최종 성능 평가 후, 추론(inference) 최적화(양자화, 프루닝) 후 서비스에 적용  \n",
      "\n",
      "---\n",
      "\n",
      "## 5. 딥러닝이 실제로 쓰이는 대표적인 사례\n",
      "\n",
      "| 분야 | 구체적 활용 예시 |\n",
      "|------|----------------|\n",
      "| **컴퓨터 비전** | 얼굴 인식, 자율주행 차량의 객체 탐지, 의료 영상에서 암 진단 |\n",
      "| **자연어 처리** | 챗봇·대화형 AI(예: ChatGPT), 기계 번역, 감성 분석, 문서 요약 |\n",
      "| **음성·음악** | 음성 인식(ASR), 텍스트‑음성 변환(TTS), 음악 생성·보정 |\n",
      "| **게임·시뮬레이션** | 강화학습 기반 게임 AI(AlphaGo, OpenAI Five) |\n",
      "| **생명과학** | 단백질 구조 예측(AlphaFold), 유전자 발현 데이터 분석 |\n",
      "| **산업·제조** | 결함 검출, 예측 유지보수, 로봇 제어 |\n",
      "| **금융** | 신용 점수 예측, 사기 탐지, 알고리즘 트레이딩 |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. 딥러닝을 시작할 때 흔히 마주치는 어려움과 해결 팁\n",
      "\n",
      "| 문제 | 원인 | 해결 팁 |\n",
      "|------|------|--------|\n",
      "| **과적합** | 모델이 학습 데이터에 너무 맞춰짐 | - 더 많은 데이터 확보<br>- Dropout, L2 정규화 적용<br>- 조기 종료(Early Stopping) |\n",
      "| **학습이 안 된다** (Loss가 감소 안 함) | 학습률이 너무 크거나 작음, 가중치 초기화 문제 | - 학습률을 10배 정도 조정<br>- He, Xavier 초기화 사용 |\n",
      "| **GPU 메모리 부족** | 배치 크기·모델 크기 과다 | - 배치 크기 감소<br>- 모델 압축(프루닝, 양자화) |\n",
      "| **데이터 불균형** | 특정 클래스가 현저히 적음 | - 클래스 가중치 적용<br>- 오버샘플링·언더샘플링 |\n",
      "| **실시간 추론 지연** | 모델이 너무 크거나 연산 복잡 | - 경량 모델(MobileNet, EfficientNet) 사용<br>- TensorRT, ONNX 등 최적화 도구 활용 |\n",
      "\n",
      "---\n",
      "\n",
      "## 7. 앞으로의 흐름과 연구 트렌드\n",
      "\n",
      "1. **대규모 사전학습 & 파인튜닝**  \n",
      "   - GPT‑4, PaLM, LLaMA 등 수십억·수조 파라미터 모델을 사전학습 후, 특정 작업에 맞게 작은 데이터로 파인튜닝하는 방식이 표준화되고 있습니다.\n",
      "\n",
      "2. **멀티모달 학습**  \n",
      "   - 텍스트·이미지·음성·비디오를 동시에 다루는 모델(예: CLIP, Flamingo)으로, 하나의 모델이 여러 종류의 입력을 이해하고 생성할 수 있습니다.\n",
      "\n",
      "3. **효율성·친환경 AI**  \n",
      "   - 파라미터 수를 줄이면서도 성능을 유지하는 **스파스(sparse) 모델**, **지식 증류(knowledge distillation)**, **양자화(quantization)** 등 연구가 활발합니다.\n",
      "\n",
      "4. **설명 가능성 & 안전성**  \n",
      "   - 왜 특정 결정을 내렸는지 설명하는 **XAI(eXplainable AI)** 기법과, 편향·유해 콘텐츠를 억제하는 **AI 안전** 연구가 강조됩니다.\n",
      "\n",
      "5. **생성 모델의 확장**  \n",
      "   - 텍스트‑이미지·텍스트‑비디오·텍스트‑3D 등 **멀티모달 생성** 모델이 실용 단계에 가까워지고 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 8. 간단히 직접 실습해 보기 (Python + PyTorch 예시)\n",
      "\n",
      "```python\n",
      "# 1️⃣ 라이브러리 설치\n",
      "# pip install torch torchvision\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torchvision\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# 2️⃣ 데이터 로드 (MNIST 손글씨)\n",
      "transform = transforms.Compose([transforms.ToTensor(),\n",
      "                                transforms.Normalize((0.5,), (0.5,))])\n",
      "train_set = torchvision.datasets.MNIST(root='./data',\n",
      "                                       train=True,\n",
      "                                       download=True,\n",
      "                                       transform=transform)\n",
      "train_loader = torch.utils.data.DataLoader(train_set,\n",
      "                                           batch_size=64,\n",
      "                                           shuffle=True)\n",
      "\n",
      "# 3️⃣ 간단한 CNN 모델 정의\n",
      "class SimpleCNN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)   # 28x28 → 28x28\n",
      "        self.pool  = nn.MaxPool2d(2, 2)                          # 28x28 → 14x14\n",
      "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # 14x14 → 14x14\n",
      "        self.fc1   = nn.Linear(64*7*7, 128)\n",
      "        self.fc2   = nn.Linear(128, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = self.pool(F.relu(self.conv1(x)))   # -> [batch,32,14,14]\n",
      "        x = self.pool(F.relu(self.conv2(x)))   # -> [batch,64,7,7]\n",
      "        x = x.view(-1, 64*7*7)                  # flatten\n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = self.fc2(x)\n",
      "        return x\n",
      "\n",
      "model = SimpleCNN()\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
      "\n",
      "# 4️⃣ 학습 루프 (1 epoch)\n",
      "model.train()\n",
      "for images, labels in train_loader:\n",
      "    optimizer.zero_grad()\n",
      "    outputs = model(images)\n",
      "    loss = criterion(outputs, labels)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "\n",
      "print('학습이 끝났습니다! 마지막 배치 손실:', loss.item())\n",
      "```\n",
      "\n",
      "> 위 코드는 **MNIST** 데이터셋에 2개의 컨볼루션 층을 가진 작은 CNN을 학습시키는 가장 기본적인 예시입니다.  \n",
      "> 실제 프로젝트에서는 **데이터 증강**, **검증 루프**, **학습률 스케줄링** 등을 추가해 성능을 크게 끌어올릴 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 9. 마무리 정리\n",
      "\n",
      "- **딥러닝은** 다층 신경망을 이용해 복잡한 비선형 관계를 자동으로 학습하는 기술이며, **대규모 데이터와 고성능 연산 자원**이 있으면 강력한 성능을 발휘합니다.  \n",
      "- 핵심은 **층(layer)·활성화·가중치·역전파**라는 네 가지 기본 요소이며, 이를 바탕으로 **CNN, RNN, Transformer, GAN** 등 다양한 아키텍처가 파생되었습니다.  \n",
      "- 실제 적용 시에는 **데이터 전처리·모델 설계·학습·검증·배포** 전 과정을 체계적으로 관리해야 하며, **과적합 방지·효율성 최적화** 같은 실무적 이슈를 함께 고민해야 합니다.  \n",
      "\n",
      "궁금한 점이 더 있으면 언제든 물어보세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"딥러닝이 뭐야?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "나는 프로그래밍을 좋아해요.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "태양계에는 8개의 행성이 있습니다. \n",
      "\n",
      "1.  수성: 태양과 가장 가까운 행성으로, 표면이 암석으로 구성되어 있고 극도로 높은 온도와 낮은 온도가 반복됩니다.\n",
      "2.  금성: 태양계에서 두 번째로 가까운 행성으로, 두꺼운 대기로 인해 극심한 온실 효과가 발생하여 매우 뜨겁습니다.\n",
      "3.  지구: 우리가 사는 행성으로, 물과 대기가 있어 생명체가 존재할 수 있습니다.\n",
      "4.  화성: 태양계에서 네 번째로 가까운 행성으로, 붉은색의 모래사막으로 덮여 있고 물과 생명체의 존재 가능성이 있습니다.\n",
      "5.  목성: 태양계에서 가장 큰 행성으로, 가스 거인이며 강력한 자기장과 수많은 위성을 가지고 있습니다.\n",
      "6.  토성: 태양계에서 두 번째로 큰 행성으로, 가스 거인이며 아름다운 고리를 가지고 있습니다.\n",
      "7.  천왕성: 태양계에서 일곱 번째로 가까운 행성으로, 가스 거인이며 자전축이 기울어져 있어 극단적인 기후 변화를 경험합니다.\n",
      "8.  해왕성: 태양계에서 가장 먼 행성으로, 가스 거인이며 강한 바람과 극적인 기후 변화를 가지고 있습니다.\n",
      "\n",
      "이러한 행성들은 각각 고유한 특징과 성질을 가지고 있으며, 태양계에서 중요한 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000289268F4950>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000289268C7470>, root_client=<openai.OpenAI object at 0x0000028925CCB200>, root_async_client=<openai.AsyncOpenAI object at 0x00000289268F4500>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "## 태양계 행성 8개 (간단 정리)\n",
      "\n",
      "| 순서(태양에서 멀어지는 순서) | 행성 | 크기·특징 | 대표적인 사실 |\n",
      "|---|---|---|---|\n",
      "| 1 | **수성** | 가장 작고 뜨거운 행성 | 태양에 가장 가까워 하루가 58일 정도 (자전은 59일) |\n",
      "| 2 | **금성** | “지구의 쌍둥이”라 불리지만 온도가 매우 높음 | 대기가 두꺼워서 온실 효과가 강해 섭씨 460도까지 올라감 |\n",
      "| 3 | **지구** | 생명체가 사는 유일한 행성 | 물이 액체 상태로 존재하고, 대기에는 산소와 질소가 많음 |\n",
      "| 4 | **화성** | “붉은 행성” | 표면에 큰 화산·협곡·극지 얼음이 있음. 과거에 물이 흐른 흔적이 발견됨 |\n",
      "| 5 | **목성** | 태양계에서 가장 큰 행성 | 가스(수소·헬륨) 행성, 대적점이라는 거대한 폭풍이 300년 이상 지속 |\n",
      "| 6 | **토성** | 고리(링)로 유명 | 아름다운 얼음과 암석으로 된 고리가 여러 개 겹쳐 있음 |\n",
      "| 7 | **천왕성** | 옆으로 누운 행성 (자전축이 거의 옆으로 기울어짐) | 푸른색은 메탄 가스 때문에, 바람이 아주 빠르게 붕돌 |\n",
      "| 8 | **해왕성** | 가장 바깥쪽 가스 행성 | 바람이 가장 빠르고, 푸른색은 메탄 때문에. 태양계에서 가장 차가운 행성 중 하나 |\n",
      "\n",
      "### 간단 포인트\n",
      "- **내행성**(수성·금성·지구·화성) → 암석(돌)으로 이루어진 작은 행성들  \n",
      "- **가스 행성**(목성·토성·천왕성·해왕성) → 대부분이 가스로 이루어져 크고 무겁다  \n",
      "- 행성들은 **태양을 중심으로 시계 방향**(북반구에서 보면)으로 돌고, 각각 고유한 공전 주기와 자전 주기가 있어요.  \n",
      "\n",
      "이 정도면 태양계 행성들을 한눈에 이해하기 쉬울 거예요! 🚀🌞\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 가을\n",
      "\n",
      " 가을에 발생하는 자연 현상:\n",
      "가을에 주로 발생하는 대표적인 지구과학 현상 3가지는 다음과 같습니다.\n",
      "\n",
      "1.  **북반구에서의 가을의 밤하늘** 가을은 여름과 비교했을 때 밤의 시간이 길어지는 시기이며, 북반구에서 가을 밤하늘을 관찰할 때 북두칠성의 모습은 북극별인 폴라리스로 가는 길잡이처럼 보입니다. \n",
      "2.  **가을의 은하수** 가을 밤하늘에서 은하수를 찾아볼 수 있습니다. 가을의 밤하늘에서 은하수를 관측할 수 있는 이유는 가을 밤하늘의 주요 별자리들이 남쪽 하늘에 있기 때문입니다. \n",
      "3.  **가을의 기상 현상: 이슬비** 이슬비는 가을에 자주 발생하는 기상 현상입니다. 이슬비는 가을의 아침과 저녁에 발생하는 얇은 안개와 유사한 현상으로, 밤에 지표면의 온도가 떨어지면서 물 분자가 응결되어 발생하는 것입니다. 밤에 기온이 낮아지면서 지표면에서 발생한 수분이 기체에서 액체로 바뀌어 이슬방울이 형성되며 이슬비가 발생합니다.\n",
      "\n",
      "이러한 현상들은 가을에 자주 발생하는 대표적인 지구과학 현상입니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season_name = get_current_season(\"north\")  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season_name}\")\n",
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season_name}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season_name}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1377.98원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: 최근 원/달러 환율이 1,377.98원 수준으로 상승한 배경에는 여러 가지 경제 요인들이 있습니다. 아래는 주요 분석 포인트입니다.\n",
      "\n",
      "### 1. **글로벌 경제 상황**\n",
      "- **미국 경제의 견조한 성장세**: 미국 경제가 여전히 견조한 성장세를 보이고 있으며, 노동시장이 탄탄한 상태를 유지하고 있습니다. 이는 미국 연방준비제도(Fed)의 긴축 정책을 뒷받침하고 있으며, 결과적으로 달러화의 가치를 높이고 있습니다.\n",
      "- **금리 인상 지속**: Fed의 금리 인상 정책이 당분간 지속될 것이라는 기대로 인해 달러화가 다른 통화 대비 강세를 보이고 있습니다. 높은 금리는 투자자들에게 더 높은 수익률을 제공하기 때문에 달러화 수요를 증가시킵니다.\n",
      "\n",
      "### 2. **국내 경제 상황**\n",
      "- **경기 둔화**: 한국의 경우, 경기 둔화 우려가 커지고 있습니다. 수출 감소, 반도체 업황 부진 등이 영향을 미치고 있습니다. 이는 원화 가치 하락 요인 중 하나입니다.\n",
      "- **외국인 자금 유출**: 최근 외국인 투자자들이 한국 주식시장에서 자금을 순유출하고 있는 점도 원화 약세에 영향을 주고 있습니다. 외국인의 자금 유출은 원화 수요 감소로 이어져 환율 상승 압력을 가중시킵니다.\n",
      "\n",
      "### 3. **에너지 가격 상승**\n",
      "- **유가 상승**: 국제 유가가 상승세를 유지하면서 한국의 무역수지에 부담을 주고 있습니다. 원유 수입 의존도가 높은 한국은 유가 상승이 경상수지에 부정적인 영향을 미치고 있으며, 이는 원화 가치에 부정적입니다.\n",
      "\n",
      "### 4. **통화 정책 차이**\n",
      "- **한국은행의 완화적 통화정책**: 한국은행이 여전히 완화적 통화정책을 유지하고 있는 반면, Fed는 긴축 정책을 지속하고 있습니다. 이러한 통화 정책의 차이도 달러화 강세와 원화 약세를 부추기고 있습니다.\n",
      "\n",
      "### 전망\n",
      "- **단기적으로 높은 환율 유지**: 전문가들은 단기적으로 높은 환율이 유지될 가능성이 있다고 보고 있습니다. 글로벌 경제 불확실성, 미국의 고금리 정책 지속, 한국의 경기 둔화 등이 원화 약세를 계속 견인할 수 있습니다.\n",
      "- **원화 반등 가능성**: 그러나 원화 반등의 여지도 있습니다. 한국 정부의 경제 정책 발표, 수출 지표 개선, 국제 유가의 안정화 등이 긍정적인 신호로 작용할 수 있습니다.\n",
      "\n",
      "### 투자 및 환전 전략\n",
      "- **환율 변동 위험 관리**: 기업과 개인 투자자들은 환율 변동에 따른 위험을 관리하기 위해 환헤지 상품 등을 활용할 필요가 있습니다. 예측 가능한 환율 변동은 수출입 기업들에게 중요한 고려 요소입니다.\n",
      "- **경제 지표 모니터링**: 향후 경제 지표 발표와 글로벌 경제 상황을 주의 깊게 모니터링하는 것이 중요합니다. 미국의 CPI, 실업률 지표와 한국의 수출입 동향 등이 환율에 큰 영향을 줄 수 있습니다.\n",
      "\n",
      "이러한 분석을 바탕으로 환율 변동은 다양한 경제 요인에 의해 좌지우지되므로, 최신 정보를 꾸준히 확인하고 전략을 세우는 것이 중요합니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
