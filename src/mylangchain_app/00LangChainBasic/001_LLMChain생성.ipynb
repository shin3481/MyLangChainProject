{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_t\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리를 쉽게 설명해 드리겠습니다.\\n\\n1. **데이터 수집**: 인공지능 모델은 대량의 데이터를 수집하여 학습합니다. 이 데이터는 문제에 대한 답을 포함하거나 레이블링된 형태로 제공됩니다.\\n\\n2. **데이터 전처리**: 수집된 데이터를 정제하고 가공하여 모델이 학습하기에 적합한 형태로 만듭니다.\\n\\n3. **모델 초기화**: 인공지능 모델은 초기 가중치와 편향으로 시작합니다. 이 가중치와 편향은 모델이 학습하면서 조정됩니다.\\n\\n4. **예측**: 모델은 입력 데이터를 받아 예측 결과를 출력합니다.\\n\\n5. **오차 계산**: 모델의 예측 결과와 실제 답을 비교하여 오차를 계산합니다.\\n\\n6. **가중치 업데이트**: 오차를 최소화하기 위해 모델의 가중치와 편향을 업데이트합니다. 이를 통해 모델은 학습을 진행합니다.\\n\\n7. **반복**: 4\\\\~6단계를 반복하여 모델의 성능을 향상시킵니다.\\n\\n이를 통해 인공지능 모델은 데이터로부터 패턴을 학습하고, 새로운 입력에 대해 예측을 수행할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 232, 'prompt_tokens': 24, 'total_tokens': 256, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.20143151, 'prompt_time': 0.000202207, 'completion_time': 0.53752668, 'total_time': 0.537728887}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-09d5ea4a-a10c-48bc-9b2b-308914192764', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--5f0d7d55-7c4b-4bd7-84f4-4d167f6d8774-0' usage_metadata={'input_tokens': 24, 'output_tokens': 232, 'total_tokens': 256, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1.  **데이터 수집**: 인공지능 모델을 학습시키기 위해서는 많은 양의 데이터가 필요합니다. 이 데이터는 문제에 따라 달라지며, 예를 들어 이미지 분류 모델을 학습시키기 위해서는 많은 양의 이미지 데이터가 필요합니다.\n",
      "2.  **데이터 전처리**: 수집한 데이터를 모델에 입력하기 전에 전처리 과정을 거칩니다. 이 과정에서는 데이터를 정제하고, 변환하여 모델에 적합한 형태로 만듭니다.\n",
      "3.  **모델 선택**: 인공지능 모델에는 여러 가지 유형이 있습니다. 예를 들어, 신경망, 의사결정 트리, 선형 회귀 등이 있습니다. 각 모델은 특정 문제에 적합하며, 모델 선택은 문제와 데이터에 따라 달라집니다.\n",
      "4.  **모델 학습**: 선택한 모델에 전처리된 데이터를 입력하여 모델을 학습시킵니다. 이 과정에서는 모델이 데이터를 분석하고, 패턴을 학습하며, 예측을 수행할 수 있도록 합니다. 모델 학습에는 여러 가지 방법이 있으며, 예를 들어, 지도 학습, 비지도 학습, 강화 학습 등이 있습니다.\n",
      "5.  **모델 평가**: 학습된 모델을 평가하여 성능을 확인합니다. 이 과정에서는 모델의 예측 정확도, 오차율 등을 평가하여 모델의 성능을 측정합니다.\n",
      "6.  **모델 개선**: 모델의 성능이 만족스럽지 않은 경우, 모델을 개선합니다. 이 과정에서는 모델의 구조를 변경하거나, 하이퍼파라미터를 조정하여 모델의 성능을 향상시킵니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 이미지를 분류하는 인공지능 모델을 학습시키는 경우를 생각해 봅시다.\n",
      "\n",
      "*   데이터 수집: 고양이와 강아지의 이미지를 수집합니다.\n",
      "*   데이터 전처리: 이미지를 정제하고, 변환하여 모델에 적합한 형태로 만듭니다.\n",
      "*   모델 선택: 이미지 분류에 적합한 신경망 모델을 선택합니다.\n",
      "*   모델 학습: 전처리된 이미지를 입력하여 모델을 학습시킵니다.\n",
      "*   모델 평가: 학습된 모델을 평가하여 성능을 확인합니다.\n",
      "*   모델 개선: 모델의 성능이 만족스럽지 않은 경우, 모델을 개선합니다.\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 학습하여 패턴을 인식하고, 예측을 수행할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \\n\\n기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 사진을 고양이와 아닌 고양이로 분류하는 모델을 만든다고 가정해 보겠습니다.\\n\\n1. **데이터 수집**: 수많은 고양이 사진과 고양이가 아닌 사진들을 수집합니다.\\n2. **데이터 준비**: 이 사진들을 컴퓨터가 처리할 수 있는 형태로 변환합니다.\\n3. **모델 초기화**: 모델은 처음에 무작위로 설정된 가중치와 편향값을 가지고 시작합니다. 이 가중치와 편향값이 사진의 특징을 어떻게 추출하고 분류할지를 결정합니다.\\n\\n**학습 과정**:\\n\\n- **예측**: 모델에 사진을 입력하면, 모델은 현재의 가중치와 편향값을 사용하여 고양이일지 아닌지 예측합니다.\\n- **오차 계산**: 예측 결과와 실제 레이블(고양이 또는 아니요) 간의 차이를 계산합니다. 이 차이를 손실(loss)이라고 합니다.\\n- **가중치 업데이트**: 모델은 손실을 최소화하는 방향으로 가중치와 편향값을 조금씩 업데이트합니다. 이 과정은 역전파(backpropagation) 알고리즘을 통해 이루어집니다.\\n\\n**반복**:\\n\\n- 모델은 많은 사진들에 대해 예측하고, 오차를 계산하고, 가중치를 업데이트하는 과정을 반복합니다.\\n- 이 반복적인 과정 속에서 모델은 데이터의 패턴을 학습하고, 고양이 사진을 더 잘 분류할 수 있게 됩니다.\\n\\n**수렴**:\\n\\n- 학습이 진행됨에 따라, 모델의 손실은 줄어들고, 모델의 정확도는 높아집니다. 결국, 모델은 새로운 사진을 봤을 때, 스스로 고양이인지 아닌지 잘 분류할 수 있게 됩니다.\\n\\n이처럼 인공지능 모델은 다양한 데이터 포인트를 통해 반복적으로 학습하며, 그 데이터에 내재된 패턴을 학습하여 새로운, 보지 못한 데이터에 대해서도 좋은 성능을 발휘할 수 있게 됩니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 398, 'prompt_tokens': 36, 'total_tokens': 434, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.200029734, 'prompt_time': 0.000624199, 'completion_time': 0.932581365, 'total_time': 0.933205564}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-beb0b8d5-9c86-48b6-b150-a73599487cd7', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--bb2d530c-78d9-4ce6-a06a-55be651de0c2-0' usage_metadata={'input_tokens': 36, 'output_tokens': 398, 'total_tokens': 434, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것입니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델에 고양이와 강아지의 사진을 많이 보여주면서 '이것은 고양이야', '이것은 강아지야'라고 알려주면, 모델은 이 사진들의 특징을 분석하기 시작합니다.\n",
      "\n",
      "고양이 사진에는 고양이의 특징인 귀가 있고, 강아지 사진에는 강아지 귀가 있습니다. 모델은 이 특징들을 학습하면서 고양이와 강아지를 구분하는 기준을 만듭니다.\n",
      "\n",
      "이렇게 모델이 학습하는 과정을 수식으로 나타내면, 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 많은 양의 데이터(고양이와 강아지의 사진)를 수집합니다.\n",
      "2. **데이터 전처리**: 데이터를 컴퓨터가 처리할 수 있는 형태로 변환합니다.\n",
      "3. **모델 정의**: 모델의 구조를 정의합니다. (예: 신경망)\n",
      "4. **손실 함수 정의**: 모델의 성능을 평가하는 손실 함수를 정의합니다. (예: 크로스 엔트로피)\n",
      "5. **최적화 알고리즘 선택**: 모델의 가중치를 업데이트하는 최적화 알고리즘을 선택합니다. (예: 경사 하강법)\n",
      "6. **학습**: 모델을 학습합니다. (예: 고양이/강아지 분류)\n",
      "\n",
      "학습 과정에서는 모델의 가중치를 업데이트하면서 손실 함수를 최소화하는 방향으로 학습합니다. 이렇게 학습한 모델은 새로운 사진을 보여주었을 때, 고양이인지 강아지인지 분류할 수 있습니다.\n",
      "\n",
      "이러한 학습 원리는 다양한 인공지능 모델에 적용할 수 있으며, 모델의 성능을 높이는데 중요한 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 사람의 뇌는 경험을 통해 학습하고, 이를 통해 새로운 상황에 대처할 수 있습니다. 인공지능 모델도 데이터를 통해 학습하고, 이를 통해 새로운 입력에 대한 출력을 예측할 수 있습니다.\n",
      "\n",
      "구체적으로 설명하면, 인공지능 모델의 학습 과정은 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해서는大量的한 데이터가 필요합니다. 이 데이터는 문제에 대한 입력과 출력으로 구성됩니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터는 모델에 입력되기 전에 전처리 과정을 거칩니다. 이 과정에서는 데이터의 품질을 높이고, 데이터의 크기를 줄이는 등의 작업이 수행됩니다.\n",
      "\n",
      "3. **모델 선택**: 인공지능 모델에는 여러 가지 유형이 있습니다. 문제의 성격에 따라 적합한 모델을 선택해야 합니다.\n",
      "\n",
      "4. **학습**: 선택된 모델에 전처리된 데이터를 입력하여 학습을 시작합니다. 이 과정에서 모델은 데이터의 패턴을 학습하고, 입력과 출력 사이의 관계를 발견하려고 합니다.\n",
      "\n",
      "5. **평가**: 학습이 완료된 후, 모델의 성능을 평가합니다. 이를 통해 모델의 정확도를 측정하고, 추가적인 조정이 필요한지 결정할 수 있습니다.\n",
      "\n",
      "6. **튜닝**: 모델의 성능이 만족스럽지 않은 경우, 모델의 하이퍼파рамет수를 조정하거나, 학습 데이터를 추가하는 등의 방법을 통해 모델을 개선할 수 있습니다.\n",
      "\n",
      "예를 들어, 이미지 분류 모델을 학습시키는 경우, 고양이와 강아지의 사진을大量的으로 수집하고, 이를 통해 모델이 고양이와 강아지를 구별할 수 있도록 학습시킵니다. 학습이 완료된 후, 새로운 이미지를 입력하면 모델은 이를 고양이 또는 강아지로 분류할 수 있습니다.\n",
      "\n",
      "이러한 학습 원리는 다양한 인공지능 모델에 적용될 수 있으며, 이를 통해 모델은 복잡한 문제를 해결할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 학습하는 과정을 간단하게 설명해 드리겠습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습하려면 많은 데이터가 필요합니다. 이 데이터는 문제에 대한 답을 포함하고 있거나, 포함하고 있지 않을 수 있습니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 모델이 이해할 수 있도록 가공하는 과정입니다. 이 과정에서는 데이터의 오류를 수정하거나, 필요한 정보를 추가하는 등의 작업이 이루어집니다.\n",
      "\n",
      "3. **모델 설정**: 인공지능 모델을 설정합니다. 모델은 데이터로부터 무엇을 배우고 싶은지에 따라 결정됩니다. 예를 들어, 이미지 인식 모델, 언어 번역 모델 등 다양한 모델이 있습니다.\n",
      "\n",
      "4. **학습**: 모델이 데이터를 분석하고, 패턴을 찾고, 규칙을 발견하는 과정입니다. 이 과정에서는 모델이 스스로 데이터를 통해 '예측'을 하게 되고, 실제 답과 비교하여 오류를 계산합니다.\n",
      "\n",
      "5. **오류 수정**: 모델의 예측과 실제 답 사이의 오류를 계산하고, 이 오류를 줄이기 위해 모델의 내부 매개변수(가중치)를 조정합니다. 이 과정은 반복적으로 이루어지며, 모델이 더 정확한 예측을 할 수 있도록 돕습니다.\n",
      "\n",
      "6. **성능 평가**: 모델의 성능을 평가합니다. 이는 모델이 얼마나 정확하게 예측을 하는지, 그리고 새로운 데이터에 대해 얼마나 잘 작동하는지를 확인하는 과정입니다.\n",
      "\n",
      "7. **최적화**: 모델의 성능을 더욱 향상시키기 위해 하이퍼파라미터를 조정하거나, 모델의 구조를 변경하는 등의 최적화 과정을 거칩니다.\n",
      "\n",
      "이러한 학습 과정을 통해 인공지능 모델은 데이터로부터 학습하여, 새로운 상황에 대해 예측하거나 결정을 내릴 수 있는 능력을 키우게 됩니다. 이 과정은 반복적이고 지속적인 개선을 통해 이루어집니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**추천 영화: 《소울 (Soul)》 (2020)**  \n",
      "\n",
      "- **장르**: 드라마·판타지·애니메이션  \n",
      "- **감독**: 피트 도크터 (Pete Docter)  \n",
      "- **주연**: 제이미 폭스(목소리), 티나 페이(목소리)  \n",
      "\n",
      "### 간단 소개\n",
      "재즈 피아니스트가 되고 싶어 하는 22세의 주인공 **조 가드너**는 어느 날 교통사고를 당하고 “영혼의 세계”로 끌려갑니다. 거기서 그는 자신의 ‘불꽃’(열정)과 ‘목적’을 찾기 위해 다양한 영혼들과 만나며, 인생과 예술, 그리고 “진짜 행복”이란 무엇인지 되돌아보게 됩니다.  \n",
      "\n",
      "### 왜 드라마 장르에 추천할 만한가?\n",
      "1. **감동적인 인생 이야기** – 성공과 실패, 꿈과 현실 사이에서 흔들리는 인간의 내면을 섬세하게 그려냅니다.  \n",
      "2. **성장과 자아 발견** – 조가 자신을 찾는 과정을 통해 관객도 자신의 삶을 되돌아볼 수 있게 합니다.  \n",
      "3. **감성적인 연출과 음악** – 재즈 사운드트랙과 아름다운 색채가 어우러져 감동을 배가시킵니다.  \n",
      "4. **전 연령층이 공감** – 어린이부터 어른까지 모두가 이해하고 공감할 수 있는 보편적인 주제를 다룹니다.  \n",
      "\n",
      "### 한 줄 평\n",
      "“삶의 의미를 찾는 여정을 따뜻하고 유머러스하게 풀어낸, 눈물과 웃음이 공존하는 감동 드라마.”  \n",
      "\n",
      "> *※ 현재 넷플릭스(Netflix)에서 스트리밍 중이며, 자막·더빙 옵션이 다양하게 제공됩니다.*\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model= \"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000026619932930>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000266199215B0>, root_client=<openai.OpenAI object at 0x0000026627D7B3E0>, root_async_client=<openai.AsyncOpenAI object at 0x0000026619922F60>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000026619932930>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000266199215B0>, root_client=<openai.OpenAI object at 0x0000026627D7B3E0>, root_async_client=<openai.AsyncOpenAI object at 0x0000026619922F60>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " The  Notebook \n",
      "\n",
      "*   **감독** : 닉  카사베츠 \n",
      "*   **캐스팅** : 라이언 고슬링  , 레이철 맥애덤스 \n",
      "*   **줄거리** : '노트북'은 니콜라스 스파크스의 소설을 원작으로 하는 영화입니다. 이 영화는1940년대와1990년대의 두 시기에 걸쳐 사랑과 인생의 복잡성을 다루고 있습니다. 노아(라이언 고슬링)와 앨리(레이철 맥애덤스)는 여름 캠프에서 처음 만나 사랑에 빠지게 됩니다. 하지만 앨리의 부모는 노아의 사회적 지위가 낮다는 이유로 두 사람의 사랑을 반대합니다. 이에 앨리는 노아와의 만남을 중단하고, 노아는 앨리를 잊지 않기 위해365일간 매일 편지를 보냅니다. 앨리는 다른 남자와 약혼하지만, 노아와의 추억을 잊지 못합니다. 마침내 앨리는 노아의 편지를 읽고, 노아를 찾아가게 됩니다. 두 사람은 다시 만나 사랑을 재확인하고, 앨리는 노아와의 약속을 지키기 위해 노아와 결혼합니다. 이 영화는 사랑, 희생, 그리고 인생의 기쁨과 슬픔을 다루고 있습니다. 아름다운 영상과 감동적인 이야기로 많은 사랑을 받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "(\"영화의 제목은 '그랜 투리스모'입니다.\\n\"\n",
      " '\\n'\n",
      " \"'그랜 투리스모'는 2013년에 개봉한 드라마 영화입니다. \\n\"\n",
      " '\\n'\n",
      " '감독은 니클라우스의 감독이 맡았습니다.\\n'\n",
      " '\\n'\n",
      " '주요 캐스팅은 올랜도 블룸, 다코타 패닝 등이 있습니다.\\n'\n",
      " '\\n'\n",
      " \"줄거리는 실제 레이싱 게임 '그랜 투리스모'를 기반으로 한 드라마 영화입니다. 이 영화는 게임에서 프로 레이싱 드라이버로 성장한 주인공 \"\n",
      " '얀 마그누센의 실화를 바탕으로 합니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
