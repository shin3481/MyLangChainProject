{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1cf819",
   "metadata": {},
   "source": [
    "#### 1. 환경 설정\n",
    "\n",
    "* ctrl + shift + p -> Python: Restart Language Server 를 선택하면 노란 warning 줄이 사라집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0cb932",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423dec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "print(TAVILY_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b09cb",
   "metadata": {},
   "source": [
    "`(2) 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54412ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67655",
   "metadata": {},
   "source": [
    "## 2. 도구 호출 (Tool Calling)\n",
    "- 도구 호출은 LLM이 특정 작업을 수행하기 위해 외부 기능을 호출하는 기능\n",
    "- 이를 통해 LLM은 외부 API 통합 등 더 복잡한 작업을 수행할 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdccc6b",
   "metadata": {},
   "source": [
    "### 2-1. 랭체인 내장 도구\n",
    "- Tavily 웹 검색 도구 (예시)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7e257",
   "metadata": {},
   "source": [
    "`(1) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "# 검색할 쿼리 설정\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "\n",
    "# Tavily 검색 도구 초기화 (최대 3개의 결과 반환)\n",
    "#web_search = TavilySearchResults(max_results=2)\n",
    "web_search = TavilySearchResults(\n",
    "    # 검색 결과의 최대 개수를 3개로 제한합니다.\n",
    "    max_results=3,\n",
    "\n",
    "    # 검색 깊이를 \"고급(advanced)\"으로 설정합니다.\n",
    "    # 일반(basic) 검색보다 더 깊이 있고 포괄적인 결과를 제공해 복잡한 질문에 더 적합합니다.\n",
    "    search_depth=\"advanced\",\n",
    "\n",
    "    # 검색 결과에 질문에 대한 요약된 답변을 포함시킵니다.\n",
    "    # 이를 통해 에이전트가 별도의 추론 없이 핵심 정보를 빠르게 얻을 수 있습니다.\n",
    "    include_answer=True,\n",
    "\n",
    "    # 검색 결과에 원본 웹페이지의 전체 콘텐츠를 포함시킵니다.\n",
    "    # 답변에 대한 더 자세한 맥락이나 원문이 필요할 때 유용합니다.\n",
    "    include_raw_content=True,\n",
    "\n",
    "    # 검색 결과에 관련된 이미지를 포함시킵니다.\n",
    "    # 시각적인 정보가 필요한 경우(예: 특정 장소, 제품 등) 유용합니다.\n",
    "    include_images=True,\n",
    ")\n",
    "\n",
    "# 웹 검색 실행\n",
    "search_results = web_search.invoke(query)\n",
    "\n",
    "# 검색 결과 출력 [dict, dict]\n",
    "for result in search_results:\n",
    "    print(type(result))\n",
    "    print(result.keys())  \n",
    "    print(result['score'], result['url'])\n",
    "    print(\"-\" * 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6791575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(web_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(web_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(web_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(web_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b600d9",
   "metadata": {},
   "source": [
    "`(2) 도구(tool) 호출하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# from langchain_upstage import ChatUpstage\n",
    "# llm = ChatUpstage(\n",
    "#         model=\"solar-pro\",\n",
    "#         base_url=\"https://api.upstage.ai/v1\",\n",
    "#         temperature=0.5\n",
    "#     )\n",
    "print(llm.model_name)\n",
    "\n",
    "# 웹 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=[web_search])\n",
    "print(type(llm_with_tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출이 필요 없는 LLM 호출을 수행\n",
    "query = \"안녕하세요?\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls) #[]\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8df009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "#query = \"최근에 가장 인기있는 파스타 식당을 추천해주세요\"\n",
    "ai_message = llm_with_tools.invoke(query)\n",
    "print(type(ai_message))\n",
    "\n",
    "# AIMessage의 속성 확인\n",
    "pprint(vars(ai_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pprint(ai_message)\n",
    "print(\"#\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_message.content)\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_message.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = ai_message.tool_calls[0]\n",
    "\n",
    "pprint(tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86835305",
   "metadata": {},
   "source": [
    "`(3) 도구(tool) 실행하기`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75bf7f",
   "metadata": {},
   "source": [
    "##### Tool 직접 호출하여 바로 ToolMessage 객체 생성\n",
    "\n",
    "* 이 방법은 도구를 직접 호출하여 ToolMessage 객체를 생성한다.\n",
    "* 가장 간단하고 직관적인 방법으로, LangChain의 추상화를 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool_call  {'name': 'tavily_search_results_json', 'args': {'query': 'wine pairing with steak'}, 'id': 'call_LrHyxTadqHDjW7J6LOWEaoSi', 'type': 'tool_call'}\n",
    "tool_message = web_search.invoke(tool_call)\n",
    "print(type(tool_message))\n",
    "\n",
    "# 특정 속성들만 확인\n",
    "print(\"\\n=== ToolMessage 객체의 주요 속성들 ===\")\n",
    "attributes = ['content', 'tool_call_id', 'name', 'type', 'additional_kwargs']\n",
    "for attr in attributes:\n",
    "    if hasattr(tool_message, attr):\n",
    "        print(f\"{attr}: {getattr(tool_message, attr)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d47ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tool_message.content))\n",
    "pprint(tool_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tool_message.tool_call_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01309400",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tool_message.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e71c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 실행 - 도구 호출이 여러 개인 경우\n",
    "\n",
    "# web_serarch 변수는 TavilySearchResults 객체\n",
    "tool_messages = web_search.batch(ai_message.tool_calls)\n",
    "\n",
    "print(tool_messages)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20257ba",
   "metadata": {},
   "source": [
    "`(4) @chain 데코레이터를 사용하여 RunnableLambda로 생성하기`\n",
    "* @chain 데코레이터를 사용하여 Tavily를 호출하는 TavilySearchResults 객체와 LLM을 연결하여 RunnableLambda 객체로 생성하기\n",
    "\n",
    "* @chain 데코레이터를 선언한 web_search_chain 함수의 파라미터 이름이 config여야 하는 이유: \n",
    "    * @chain 데코레이터가 config라는 이름만 특별히 인식하도록 설계되었습니다.\n",
    "    * config 생략 가능한 이유: @chain이 자동으로 기본 RunnableConfig()를 생성해서 전달하기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5de654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "from pprint import pprint\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Tavily 검색 도구 초기화 (최대 3개의 결과 반환)\n",
    "tavily_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[tavily_tool])\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "print(type(llm_chain))\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "# web_search_chain() 함수는 StructuredTool 객체이다.\n",
    "@chain\n",
    "def web_search_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msgs = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msgs: \\n\", ai_msgs) #AIMessage\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    tool_msgs = tavily_tool.batch(ai_msgs.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs) #ToolMessage \n",
    "    \n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msgs, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "# chain을 호출하는 함수 호출\n",
    "print('====>' , type(web_search_chain))\n",
    "response = web_search_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f49a9f",
   "metadata": {},
   "source": [
    "### 2-2. 사용자 정의 도구\n",
    "* @tool decorator를 통해 사용자 정의 도구를 정의할 수 있음\n",
    "* @tool 데코레이터를 사용하여 Tavily를 호출하는 tavily_search_func 함수를 StructuredTool로 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c058ff5",
   "metadata": {},
   "source": [
    "`(1) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Tool 정의  tavily_search_func 은 StructuredTool 타입이다.\n",
    "@tool\n",
    "def tavily_search_func(query: str) -> str:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    #doc 변수가 dict 타입, ['title', 'url', 'content', 'score', 'raw_content']\n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "        ])\n",
    "\n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(llm.model_name)\n",
    "llm_with_tools = llm.bind_tools(tools=[tavily_search_func])\n",
    "print(type(llm_with_tools))\n",
    "\n",
    "query = \"최근에 가장 인기있는 파스타 식당을 추천해주세요\"\n",
    "ai_message = llm_with_tools.invoke(query)\n",
    "print(ai_message.tool_calls)\n",
    "\n",
    "pprint(ai_message)\n",
    "\n",
    "print(type(tavily_search_func))\n",
    "tool_message = tavily_search_func.invoke(ai_message.tool_calls[0])\n",
    "print(tool_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d5144",
   "metadata": {},
   "source": [
    "### 2-3. Runnable 객체를 도구(tool) 변환\n",
    "- 문자열이나 dict 입력을 받는 Runnable을 도구로 변환\n",
    "- as_tool() 메서드를 사용\n",
    "- [WikipediaLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.wikipedia.WikipediaLoader.html) 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34b84a",
   "metadata": {},
   "source": [
    "- wikipedia 설치\n",
    "```python\n",
    "    poetry add wikipedia\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈들을 가져옵니다.\n",
    "from langchain_community.document_loaders import WikipediaLoader  # 위키피디아에서 문서를 불러오는 로더\n",
    "from langchain_core.documents import Document                     # LangChain 문서 객체\n",
    "from langchain_core.runnables import RunnableLambda             # 일반 함수를 LangChain의 Runnable로 변환\n",
    "from pydantic import BaseModel, Field                           # 데이터 유효성 검사 및 스키마 정의를 위한 Pydantic\n",
    "from typing import List                                         # 타입 힌트를 위한 List\n",
    "# dedent() 함수를 가져옵니다. 이 함수는 문자열의 들여쓰기를 제거하는 역할을 합니다.\n",
    "from textwrap import dedent\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하는 함수를 정의합니다.\n",
    "def search_wiki_func(input_data: dict) -> List[Document]:\n",
    "    \"\"\"사용자의 입력(query)을 기반으로 위키피디아 문서를 검색하고 지정된 개수(k)만큼 반환합니다.\"\"\"\n",
    "    # input_data 딕셔너리에서 'query' 값을 가져와 검색어로 사용합니다.\n",
    "    query = input_data[\"query\"]\n",
    "    # input_data에서 'k' 값을 가져옵니다. 'k'가 없으면 기본값 2를 사용합니다.\n",
    "    k = input_data.get(\"k\", 2)\n",
    "    \n",
    "    # 지정된 검색어와 문서 개수(k), 언어('ko' for 한국어)를 설정하여 WikipediaLoader를 초기화합니다.\n",
    "    wiki_loader = WikipediaLoader(query=query, load_max_docs=k, lang=\"ko\")\n",
    "    # 로더를 실행하여 위키피디아 문서를 불러옵니다.\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    # 불러온 문서 목록을 반환합니다. wiki_docs는 List[Document] 타입이다.\n",
    "    return wiki_docs\n",
    "\n",
    "# 도구 호출에 사용될 입력 스키마(데이터 구조)를 Pydantic을 이용해 정의합니다.\n",
    "class WikiSearchSchema(BaseModel):\n",
    "    \"\"\"위키피디아 검색을 위한 입력 스키마.\"\"\"\n",
    "    # 검색어를 나타내는 필드. ...은 필수 필드임을 의미합니다.\n",
    "    query: str = Field(..., description=\"위키피디아에서 검색할 질의어\")\n",
    "    # 반환할 문서의 개수를 나타내는 필드. 기본값은 2입니다.\n",
    "    k: int = Field(2, description=\"반환할 문서의 개수 (기본값은 2)\")\n",
    "\n",
    "# RunnableLambda를 사용하여 함수(search_wiki)를 LangChain의 Runnable 객체로 변환합니다.\n",
    "# 이를 통해 함수를 LangChain의 체인(chain)이나 에이전트 도구로 활용할 수 있습니다.\n",
    "runnable = RunnableLambda(search_wiki_func)\n",
    "print(type(runnable))\n",
    "\n",
    "# Runnable 객체를 도구(tool)로 변환합니다. wiki_search는 StructuredTool 객체이다.\n",
    "wiki_search = runnable.as_tool(\n",
    "    # 도구의 이름을 'wiki_search'로 설정합니다.\n",
    "    name=\"wiki_search_tool\",\n",
    "    # 도구의 설명을 지정합니다. dedent() 함수를 사용해 들여쓰기를 제거하여 깔끔하게 만듭니다.\n",
    "    description=dedent(\"\"\"\n",
    "        위키피디아 정보를 검색해야 할 때 이 도구를 사용하세요.\n",
    "        사용자의 질의와 관련된 위키피디아 문서를 검색하여 지정된 개수만큼 반환합니다.\n",
    "        일반적인 지식이나 배경 정보가 필요할 때 유용합니다.\n",
    "    \"\"\"),\n",
    "    # 도구의 입력 스키마를 WikiSearchSchema로 지정하여 입력의 유효성을 검사합니다.\n",
    "    args_schema=WikiSearchSchema\n",
    ")\n",
    "print(type(wiki_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 속성\n",
    "print(\"자료형: \")\n",
    "print(type(wiki_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ff3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위키 검색 Tool 호출\n",
    "query = \"파스타의 유래\"\n",
    "wiki_results = wiki_search.invoke({\"query\":query})\n",
    "# wiki_results[0])는 Document\n",
    "print(type(wiki_results[0]))\n",
    "\n",
    "# 검색 결과 출력\n",
    "for result in wiki_results:\n",
    "    print(result.metadata['source'])  \n",
    "    print(result.page_content[:100])\n",
    "    print(\"-\" * 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b812a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "print(llm.model_name)\n",
    "print('==> tavily_search_func = ' , type(tavily_search_func))\n",
    "print('==> wiki_search = ' , type(wiki_search))\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools=[tavily_search_func, wiki_search])\n",
    "print(type(llm_with_tools))\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "ai_msgs = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msgs)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msgs.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msgs.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06d2ed",
   "metadata": {},
   "source": [
    "`(2) LCEL 체인`\n",
    "- 위키피디아 문서를 검색하고 내용을 요약하는 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하고 텍스트로 반환하는 함수 \n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "\n",
    "    formatted_docs =[\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "        ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "# 요약 프롬프트 템플릿\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary:\"\n",
    ")\n",
    "\n",
    "# LLM 및 요약 체인 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    | summary_prompt | llm | StrOutputParser() \n",
    ")\n",
    "print(type(summary_chain))\n",
    "\n",
    "# 요약 테스트 \n",
    "summarized_text = summary_chain.invoke({\"query\":\"파스타의 유래\"})\n",
    "pprint(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ac080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field                           # 데이터 유효성 검사 및 스키마 정의를 위한 Pydantic\n",
    "from typing import List                                         # 타입 힌트를 위한 List\n",
    "# dedent() 함수를 가져옵니다. 이 함수는 문자열의 들여쓰기를 제거하는 역할을 합니다.\n",
    "from textwrap import dedent\n",
    "\n",
    "# 도구 호출에 사용할 입력 스키마 정의 \n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "# as_tool 메소드를 사용하여 도구 객체로 변환\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(wiki_summary))\n",
    "print(\"1\",\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_summary.name)\n",
    "print(\"2\",\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_summary.description)\n",
    "print(\"3\",\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_summary.args_schema.schema())\n",
    "print(\"4\",\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78824759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[tavily_search_func, wiki_summary])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "ai_msgs = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msgs)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msgs.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msgs.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d0b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msgs.tool_calls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbdd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 실행 \n",
    "tool_message = wiki_summary.invoke(ai_msgs.tool_calls[1])\n",
    "\n",
    "print(tool_message)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2de1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[wiki_summary])\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def wiki_summary_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    tool_msgs = wiki_summary.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = wiki_summary_chain.invoke(\"파스타의 유래에 대해서 알려주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f828547",
   "metadata": {},
   "source": [
    "### 2-4. 벡터저장소 검색기\n",
    "- @tool decorator 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9dc12",
   "metadata": {},
   "source": [
    "`(1) 문서 로드 및 인덱싱`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da1d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# 메뉴판 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"../data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 분할 (Chunking)\n",
    "# 이 함수는 긴 문서(document)를 더 작은 단위인 '메뉴 항목(menu_items)'으로 분할합니다.\n",
    "# LangChain의 RAG(Retrieval-Augmented Generation) 시스템에서 정확한 정보를 찾기 위해\n",
    "# 문서를 의미 있는 청크(chunk)로 나누는 과정입니다.\n",
    "import re\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def split_menu_items(document):\n",
    "    \"\"\"\n",
    "    하나의 큰 문서(document)에서 각 메뉴 항목을 분리하여\n",
    "    각각을 별도의 Document 객체로 반환하는 함수입니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 정규표현식(regular expression)을 정의합니다. \n",
    "    # 이 패턴은 \"숫자. \"로 시작하고, 다음 \"숫자. \" 또는 문서의 끝이 나타날 때까지의 텍스트를 찾습니다.\n",
    "    # r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "    #   - r'...' : raw string으로, \\ 문자를 그대로 인식하게 합니다.\n",
    "    #   - (\\d+\\.\\s.*?) : 캡처 그룹(괄호).\n",
    "    #     - \\d+ : 하나 이상의 숫자.\n",
    "    #     - \\. : 마침표(.) 문자.\n",
    "    #     - \\s : 공백 문자.\n",
    "    #     - .*? : 최소 일치(non-greedy)로 어떤 문자든 0개 이상.\n",
    "    #   - (?=\\n\\n\\d+\\.|$) : 전방탐색(lookahead).\n",
    "    #     - 다음 패턴이 뒤따르는 위치를 찾지만, 실제 매치 결과에는 포함하지 않습니다.\n",
    "    #     - \\n\\n\\d+\\. : 두 개의 줄바꿈과 \"숫자. \"가 이어지는 부분.\n",
    "    #     - | : '또는'을 의미합니다.\n",
    "    #     - $ : 문자열의 끝.\n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "    \n",
    "    # document의 page_content(문서 내용)에서 위에서 정의한 패턴과 일치하는 모든 문자열을 찾아 리스트로 반환합니다.\n",
    "    # re.DOTALL 플래그는 .이 줄바꿈 문자(\\n)까지 매치하도록 합니다.\n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "    \n",
    "    # 분리된 각 메뉴 항목을 저장할 빈 리스트를 만듭니다.\n",
    "    menu_documents = []\n",
    "    \n",
    "    # enumerate()를 사용하여 각 메뉴 항목과 그 인덱스(i)를 순회합니다. 인덱스는 1부터 시작합니다.\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        # 각 메뉴 항목 텍스트에서 첫 번째 줄을 가져와 '숫자.' 부분을 제거하고 메뉴 이름을 추출합니다.\n",
    "        # 예: \"1. 불고기 덮밥\\n가격...\" -> \"불고기 덮밥\"\n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "        \n",
    "        # 새로운 LangChain Document 객체를 생성합니다.\n",
    "        menu_doc = Document(\n",
    "            # page_content에는 현재 메뉴 항목의 전체 텍스트를 할당합니다.\n",
    "            page_content=item.strip(),\n",
    "            # 문서와 관련된 메타데이터(부가 정보)를 딕셔너리 형태로 저장합니다.\n",
    "            metadata={\n",
    "                # 원본 문서의 출처(파일 경로 등)를 그대로 가져옵니다.\n",
    "                \"source\": document.metadata['source'],\n",
    "                # 메뉴의 순번을 저장합니다.\n",
    "                \"menu_number\": i,\n",
    "                # 추출한 메뉴 이름을 저장합니다.\n",
    "                \"menu_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # 새로 생성한 Document 객체를 리스트에 추가합니다. List[Document]\n",
    "        menu_documents.append(menu_doc)\n",
    "    \n",
    "    # 모든 메뉴 항목이 Document 객체로 변환된 리스트를 반환합니다.\n",
    "    return menu_documents\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a09f288",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "* OllamaEmbeddings\n",
    "    * ollama run qwen2.5:1.5b\n",
    "* UpstageEmbeddings\n",
    "    * solar-embedding-1-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "#embeddings_model = OllamaEmbeddings(model=\"qwen2.5:1.5b\") \n",
    "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "# FAISS 인덱스 생성\n",
    "menu_db = FAISS.from_documents(\n",
    "    documents=menu_documents,  #List[Document]\n",
    "    embedding=embeddings_model\n",
    ")\n",
    "\n",
    "# FAISS 인덱스 저장 (선택사항)\n",
    "menu_db.save_local(\"../db/menu_db\")\n",
    "\n",
    "\n",
    "# Retriever 생성\n",
    "menu_retriever = menu_db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    #search_kwargs={\"k\": 4}\n",
    "    search_kwargs={\"k\": 4, \"fetch_k\": 6}\n",
    ")\n",
    "\n",
    "# 쿼리 테스트\n",
    "query = \"스테이크의 가격과 특징은 무엇인가요?\"\n",
    "docs = menu_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf58d36",
   "metadata": {},
   "source": [
    "- 와인 메뉴에 대해서도 같은 작업을 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc82b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와인 메뉴 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"../data/restaurant_wine.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "wine_documents = []\n",
    "for doc in documents:\n",
    "    wine_documents += split_menu_items(doc)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"총 {len(wine_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in wine_documents:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fdf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "print(llm.model_name)\n",
    "\n",
    "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "# FAISS 인덱스 생성\n",
    "wine_db = FAISS.from_documents(\n",
    "    documents=wine_documents, \n",
    "    embedding=embeddings_model\n",
    ")\n",
    "\n",
    "# 병합된 DB 다시 저장\n",
    "wine_db.save_local(\"../db/wine_db\")\n",
    "\n",
    "wine_retriever = wine_db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 4, \"fetch_k\": 6}\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(retriever=wine_retriever, llm=llm)\n",
    "\n",
    "query = \"주요 품종이 소비뇽인 와인을 추천해주세요.\"\n",
    "docs = retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040915b",
   "metadata": {},
   "source": [
    "`(2) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# menu db 벡터 저장소 로드\n",
    "menu_db = FAISS.load_local(\n",
    "    \"../db/menu_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "@tool\n",
    "def db_search_menu_func(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=4)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(db_search_menu_func))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(db_search_menu_func.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(db_search_menu_func.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(db_search_menu_func.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# wine db 벡터 저장소 로드\n",
    "wine_db = FAISS.load_local(\n",
    "    \"../db/wine_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "@tool\n",
    "def db_search_wine_func(query: str) -> List[Document]:\n",
    "   \"\"\"\n",
    "   Securely retrieve and access authorized restaurant wine information from the encrypted database.\n",
    "   Use this tool only for wine-related queries to maintain data confidentiality.\n",
    "   \"\"\"\n",
    "   docs = wine_db.similarity_search(query, k=4)\n",
    "   if len(docs) > 0:\n",
    "      return docs\n",
    "   \n",
    "   return [Document(page_content=\"관련 와인 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(db_search_wine_func))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(db_search_wine_func.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(db_search_wine_func.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(db_search_wine_func.args_schema.schema())\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "llm_with_tools = llm.bind_tools(tools=[db_search_menu_func, db_search_wine_func])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"호주산 와인을 추천 해주세요. 그리고 시그니처 스테이크의 가격과 특징은 무엇인가요? \"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7b74a1",
   "metadata": {},
   "source": [
    "`(3) 여러 개의 도구(tool) 호출하기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tavily_search_func, wiki_summary, db_search_menu_func, db_search_wine_func]\n",
    "for tool in tools:\n",
    "    #print(type(tool))\n",
    "    print(tool.name)\n",
    "    print(tool.description)\n",
    "    print(\"-\" *30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda10de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "from langchain_upstage import ChatUpstage\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    ")\n",
    "print(llm.model_name)\n",
    "\n",
    "# 4개의 검색 도구를 LLM에 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"db_search_menu_func\":\n",
    "            tool_message = db_search_menu_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"db_search_wine_func\":\n",
    "            tool_message = db_search_wine_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)            \n",
    "\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "#query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 와인도 추천해주세요.\"\n",
    "query = \"와인 가격이 50만원 이상인 와인이 있나요?. 스테이크 메뉴도 추천해 주세요.\"\n",
    "#query = \"호주산 와인이 있나요?. 그리고 채식주의자를 위한 메뉴를 추천해 주세요. \"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "print(type(response))\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "query = \"파스타 메뉴가 있나요? 파스타의 역사 또는 유래를 알려주시고 서울 강남의 파스타 맛집도 추천해주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b78e3",
   "metadata": {},
   "source": [
    "## 3. Few-shot 프롬프팅 \n",
    "- 각 도구의 용도를 구분하여 few-shot 예제로 제시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3e6b9",
   "metadata": {},
   "source": [
    "### 3-1. Few-shot 도구 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd743c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"트러플 리조또의 가격과 특징, 그리고 어울리는 와인에 대해 알려주세요.\", name=\"example_user\"),\n",
    "    AIMessage(\"메뉴 정보를 검색하고, 위키피디아에서 추가 정보를 찾은 후, 어울리는 와인을 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"db_search_menu_func\", \"args\": {\"query\": \"트러플 리조또\"}, \"id\": \"1\"}]),\n",
    "    ToolMessage(\"트러플 리조또: 가격 ₩28,000, 이탈리아 카나롤리 쌀 사용, 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리\", tool_call_id=\"1\"),    \n",
    "    AIMessage(\"트러플 리조또의 가격은 ₩28,000이며, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다. 이제 추가 정보를 위키피디아에서 찾아보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"wiki_summary\", \"args\": {\"query\": \"트러플 리조또\", \"k\": 1}, \"id\": \"2\"}]),\n",
    "    ToolMessage(\"트러플 리조또는 이탈리아 요리의 대표적인 리조또 요리 중 하나로, 고급 식재료인 트러플을 사용하여 만든 크리미한 쌀 요리입니다. \\\n",
    "                주로 아르보리오나 카나롤리 등의 쌀을 사용하며, 트러플 오일이나 생 트러플을 넣어 조리합니다. 리조또 특유의 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 것이 특징입니다.\", tool_call_id=\"2\"),\n",
    "    AIMessage(\"트러플 리조또의 특징에 대해 알아보았습니다. 이제 어울리는 와인을 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"db_search_wine_func\", \"args\": {\"query\": \"트러플 리조또에 어울리는 와인\"}, \"id\": \"3\"}]),\n",
    "    ToolMessage(\"트러플 리조또와 잘 어울리는 와인으로는 주로 중간 바디의 화이트 와인이 추천됩니다. 1. 샤르도네: 버터와 오크향이 트러플의 풍미를 보완합니다. \\\n",
    "                2. 피노 그리지오: 산뜻한 산미가 리조또의 크리미함과 균형을 이룹니다. 3. 베르나차: 이탈리아 토스카나 지방의 화이트 와인으로, 미네랄리티가 트러플과 잘 어울립니다.\", tool_call_id=\"3\"),\n",
    "    AIMessage(\"트러플 리조또(₩28,000)는 이탈리아의 대표적인 리조또 요리 중 하나로, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다.\\\n",
    "               주요 특징으로는 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 점입니다. 고급 식재료인 트러플을 사용해 풍부한 맛과 향을 내며, \\\n",
    "              주로 아르보리오나 카나롤리 등의 쌀을 사용합니다. 트러플 리조또와 잘 어울리는 와인으로는 중간 바디의 화이트 와인이 추천됩니다. \\\n",
    "              특히 버터와 오크향이 트러플의 풍미를 보완하는 샤르도네, 산뜻한 산미로 리조또의 크리미함과 균형을 이루는 피노 그리지오,\\\n",
    "               그리고 미네랄리티가 트러플과 잘 어울리는 이탈리아 토스카나 지방의 베르나차 등이 좋은 선택이 될 수 있습니다.\", name=\"example_assistant\"),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    *examples,\n",
    "    (\"human\", \"{query}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "tools = [tavily_search_func, wiki_summary, db_search_menu_func, db_search_wine_func]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크 메뉴가 있나요? 스테이크와 어울리는 와인도 추천해주세요.\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c442be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "query = \"파스타의 유래에 대해서 알고 있나요? 서울 강남의 가장 최근 파스타 맛집을 추천해주세요.\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f10c84",
   "metadata": {},
   "source": [
    "### 3-2. 답변 생성 체인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system + f\"Today's date is {today}.\"),\n",
    "    *examples,\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        # [tavily_search_func, wiki_summary, db_search_menu_func, db_search_wine_func]\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"db_search_wine_func\":\n",
    "            tool_message = db_search_wine_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"db_search_menu_func\":\n",
    "            tool_message = db_search_menu_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)            \n",
    "\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return fewshot_search_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크 메뉴가 있나요? 스테이크와 어울리는 와인을 추천해 주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "query = \"파스타의 유래에 대해서 알고 있나요? 서울 강남의 가장 최근 파스타 맛집을 추천해주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11927ed4",
   "metadata": {},
   "source": [
    "## 4. LangChain Agent 사용\n",
    "- 유의사항: 프롬프트에 \"agent_scratchpad\",  \"input\" 변수를 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", dedent(\"\"\"\n",
    "        You are an AI assistant providing restaurant menu information and general food-related knowledge. \n",
    "        Your main goal is to provide accurate information and effective recommendations to users.\n",
    "\n",
    "        Key guidelines:\n",
    "        1. For restaurant menu information, use the search_menu tool. This tool provides details on menu items, including prices, ingredients, and cooking methods.\n",
    "        2. For general food information, history, and cultural background, utilize the wiki_summary tool.\n",
    "        3. For wine recommendations or food and wine pairing information, use the search_wine tool.\n",
    "        4. If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "        5. Provide clear and concise responses based on the search results.\n",
    "        6. If a question is ambiguous or lacks necessary information, politely ask for clarification.\n",
    "        7. Always maintain a helpful and professional tone.\n",
    "        8. When providing menu information, describe in the order of price, main ingredients, and distinctive cooking methods.\n",
    "        9. When making recommendations, briefly explain the reasons.\n",
    "        10. Maintain a conversational, chatbot-like style in your final responses. Be friendly, engaging, and natural in your communication.\n",
    "\n",
    "\n",
    "        Remember, understand the purpose of each tool accurately and use them in appropriate situations. \n",
    "        Combine the tools to provide the most comprehensive and accurate answers to user queries. \n",
    "        Always strive to provide the most current and accurate information.\n",
    "        \"\"\")),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dad12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool calling Agent 생성\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "tools = [tavily_search_func, wiki_summary, db_search_menu_func, db_search_wine_func]\n",
    "agent = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "\n",
    "# AgentExecutor 생성 \n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd37cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgentExecutor 실행\n",
    "\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\"\n",
    "agent_response = agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(agent_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb411fca",
   "metadata": {},
   "source": [
    "## 5. Gradio 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abbad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "\n",
    "def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "    try:\n",
    "        # 채팅 기록을 AI에게 전달할 수 있는 형식으로 변환\n",
    "        chat_history = []\n",
    "        for human, ai in history:\n",
    "            chat_history.append(HumanMessage(content=human))\n",
    "            chat_history.append(AIMessage(content=ai))\n",
    "        \n",
    "        # agent_executor를 사용하여 응답 생성\n",
    "        response = agent_executor.invoke({\n",
    "            \"input\": message,\n",
    "            \"chat_history\": chat_history[-2:]    # 최근 2개의 메시지 기록만을 활용 \n",
    "        })\n",
    "        \n",
    "        # agent_executor의 응답에서 최종 답변 추출\n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 사용자에게 알리고 로그 기록\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "# 예제 질문 정의\n",
    "example_questions = [\n",
    "    \"시그니처 스테이크의 가격과 특징을 알려주세요.\",\n",
    "    \"트러플 리조또와 잘 어울리는 와인을 추천해주세요.\",\n",
    "    \"해산물 파스타의 주요 재료는 무엇인가요? 서울 강남 지역에 레스토랑을 추천해주세요.\",\n",
    "    \"채식주의자를 위한 메뉴 옵션이 있나요?\"\n",
    "]\n",
    "\n",
    "# Gradio 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,\n",
    "    title=\"레스토랑 메뉴 AI 어시스턴트\",\n",
    "    description=\"메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다.\",\n",
    "    examples=example_questions,\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# 데모 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd26485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데모 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb837bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
