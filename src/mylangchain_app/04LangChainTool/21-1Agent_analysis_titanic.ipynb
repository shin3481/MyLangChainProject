{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic 생존 예측 데이터 분석\n",
    "## LangChain 에이전트를 활용한 포괄적 데이터 탐색\n",
    "\n",
    "이 노트북은 LangChain의 pandas 데이터프레임 에이전트를 사용하여 Titanic 데이터를 분석하고 생존 예측 모델을 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# poetry add langchain-experimental  \n",
    "# poetry add pandas matplotlib seaborn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"환경 설정 시작...\")\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 경고 메시지 숨기기\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:3])\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OPENAI_API_KEY가 설정되지 않았습니다. .env 파일을 확인해주세요.\")\n",
    "else:\n",
    "    print(\"OpenAI API 키가 성공적으로 로드되었습니다.\")\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])\n",
    "\n",
    "print(\"환경 설정이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"라이브러리 로드 중...\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = ['나눔고딕', 'NanumGothic', 'Malgun Gothic']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Seaborn 스타일 설정\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# pandas 옵션 설정\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"라이브러리 로드가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"데이터 로드 시작...\")\n",
    "\n",
    "# 데이터 로드\n",
    "try:\n",
    "    train = pd.read_csv('./data/titanic/train.csv')\n",
    "    test = pd.read_csv('./data/titanic/test.csv')\n",
    "    \n",
    "    print(f\"훈련 데이터 로드 완료: {train.shape}\")\n",
    "    print(f\"테스트 데이터 로드 완료: {test.shape}\")\n",
    "    print(\"데이터 로드가 성공적으로 완료되었습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Titanic 데이터 파일을 찾을 수 없습니다.\")\n",
    "    print(\"현재 디렉토리에 train.csv와 test.csv 파일을 배치해주세요.\")\n",
    "    \n",
    "    # 샘플 Titanic 데이터 생성\n",
    "    print(\"샘플 Titanic 데이터를 생성합니다...\")\n",
    "    np.random.seed(42)\n",
    "    n_samples = 891\n",
    "    \n",
    "    train = pd.DataFrame({\n",
    "        'PassengerId': range(1, n_samples + 1),\n",
    "        'Survived': np.random.choice([0, 1], n_samples, p=[0.62, 0.38]),\n",
    "        'Pclass': np.random.choice([1, 2, 3], n_samples, p=[0.24, 0.21, 0.55]),\n",
    "        'Name': [f'Name_{i}' for i in range(1, n_samples + 1)],\n",
    "        'Sex': np.random.choice(['male', 'female'], n_samples, p=[0.65, 0.35]),\n",
    "        'Age': np.random.normal(29.7, 14.5, n_samples),\n",
    "        'SibSp': np.random.choice([0, 1, 2, 3, 4, 5], n_samples, p=[0.68, 0.23, 0.06, 0.02, 0.01, 0.00]),\n",
    "        'Parch': np.random.choice([0, 1, 2, 3, 4, 5, 6], n_samples, p=[0.76, 0.13, 0.08, 0.02, 0.01, 0.00, 0.00]),\n",
    "        'Ticket': [f'Ticket_{i}' for i in range(1, n_samples + 1)],\n",
    "        'Fare': np.random.lognormal(3, 1, n_samples),\n",
    "        'Cabin': np.random.choice(['A1', 'B2', 'C3', None], n_samples, p=[0.1, 0.1, 0.1, 0.7]),\n",
    "        'Embarked': np.random.choice(['C', 'Q', 'S'], n_samples, p=[0.19, 0.09, 0.72])\n",
    "    })\n",
    "    \n",
    "    # 나이 결측값 추가 (약 20%)\n",
    "    train.loc[train.sample(frac=0.2).index, 'Age'] = np.nan\n",
    "    \n",
    "    test = train.drop(['Survived'], axis=1).head(418).copy()\n",
    "    test['PassengerId'] = range(892, 892 + 418)\n",
    "    \n",
    "    print(\"샘플 데이터 생성이 완료되었습니다.\")\n",
    "\n",
    "print(\"\\n=== 데이터 기본 정보 ===\")\n",
    "print(f\"훈련 데이터: {train.shape[0]}행 {train.shape[1]}열\")\n",
    "print(f\"테스트 데이터: {test.shape[0]}행 {test.shape[1]}열\")\n",
    "print(f\"타겟 변수: {'Survived (생존 여부)' if 'Survived' in train.columns else '없음'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"데이터 구조 분석 시작...\")\n",
    "\n",
    "# 기본 데이터 정보 확인\n",
    "print(\"=== 훈련 데이터 기본 정보 ===\")\n",
    "print(f\"데이터 크기: {train.shape}\")\n",
    "print(f\"결측값 총 개수: {train.isnull().sum().sum()}\")\n",
    "print(f\"중복된 행: {train.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n=== 테스트 데이터 기본 정보 ===\")\n",
    "print(f\"데이터 크기: {test.shape}\")\n",
    "print(f\"결측값 총 개수: {test.isnull().sum().sum()}\")\n",
    "print(f\"중복된 행: {test.duplicated().sum()}\")\n",
    "\n",
    "# 공통 컬럼과 차이점 확인\n",
    "train_cols = set(train.columns)\n",
    "test_cols = set(test.columns)\n",
    "common_cols = train_cols.intersection(test_cols)\n",
    "train_only = train_cols - test_cols\n",
    "test_only = test_cols - train_cols\n",
    "\n",
    "print(f\"\\n=== 컬럼 비교 ===\")\n",
    "print(f\"공통 컬럼: {len(common_cols)}개\")\n",
    "print(f\"훈련 데이터에만 있는 컬럼: {train_only}\")\n",
    "print(f\"테스트 데이터에만 있는 컬럼: {test_only}\")\n",
    "\n",
    "# 생존율 기본 정보\n",
    "if 'Survived' in train.columns:\n",
    "    survival_rate = train['Survived'].mean()\n",
    "    print(f\"\\n전체 생존율: {survival_rate:.1%}\")\n",
    "    print(f\"생존자: {train['Survived'].sum()}명\")\n",
    "    print(f\"사망자: {(train['Survived'] == 0).sum()}명\")\n",
    "\n",
    "print(\"\\n데이터 구조 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"데이터 전처리 함수 정의 중...\")\n",
    "\n",
    "def analyze_missing_rows(df, dataset_name=\"데이터\"):\n",
    "    \"\"\"결측치 행 분석 함수\"\"\"\n",
    "    print(f\"\\n=== {dataset_name} 결측치 행 분석 ===\")\n",
    "    \n",
    "    # 기본 정보\n",
    "    total_rows = len(df)\n",
    "    rows_with_missing = df.isnull().any(axis=1).sum()\n",
    "    rows_all_missing = df.isnull().all(axis=1).sum()\n",
    "    complete_rows = total_rows - rows_with_missing\n",
    "    \n",
    "    print(f\"전체 행 수: {total_rows:,}\")\n",
    "    print(f\"완전한 행 (결측치 없음): {complete_rows:,} ({complete_rows/total_rows*100:.1f}%)\")\n",
    "    print(f\"결측치가 있는 행: {rows_with_missing:,} ({rows_with_missing/total_rows*100:.1f}%)\")\n",
    "    print(f\"모든 값이 결측치인 행: {rows_all_missing:,}\")\n",
    "    \n",
    "    # 결측치 개수별 분포\n",
    "    missing_per_row = df.isnull().sum(axis=1)\n",
    "    if rows_with_missing > 0:\n",
    "        print(f\"\\n행별 결측치 개수 통계:\")\n",
    "        print(f\"평균: {missing_per_row.mean():.2f}\")\n",
    "        print(f\"최대: {missing_per_row.max()}\")\n",
    "        print(f\"표준편차: {missing_per_row.std():.2f}\")\n",
    "        \n",
    "        # 결측치가 많은 행들\n",
    "        worst_rows = missing_per_row.nlargest(5)\n",
    "        print(f\"\\n결측치가 가장 많은 5개 행:\")\n",
    "        for idx, count in worst_rows.items():\n",
    "            print(f\"  행 {idx}: {count}개 결측치\")\n",
    "    \n",
    "    return {\n",
    "        'total_rows': total_rows,\n",
    "        'complete_rows': complete_rows,\n",
    "        'rows_with_missing': rows_with_missing,\n",
    "        'rows_all_missing': rows_all_missing\n",
    "    }\n",
    "\n",
    "def preprocess_titanic_data(df, is_train=True):\n",
    "    \"\"\"Titanic 데이터 전처리 함수\"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    print(f\"{'훈련' if is_train else '테스트'} 데이터 전처리 시작...\")\n",
    "    \n",
    "    # 나이 결측값을 중앙값으로 채우기\n",
    "    if df_processed['Age'].isnull().sum() > 0:\n",
    "        age_median = df_processed['Age'].median()\n",
    "        df_processed['Age'].fillna(age_median, inplace=True)\n",
    "        print(f\"  Age 결측값 {df['Age'].isnull().sum()}개를 중앙값 {age_median:.1f}로 대체\")\n",
    "    \n",
    "    # Embarked 결측값을 최빈값으로 채우기\n",
    "    if df_processed['Embarked'].isnull().sum() > 0:\n",
    "        embarked_mode = df_processed['Embarked'].mode()[0]\n",
    "        df_processed['Embarked'].fillna(embarked_mode, inplace=True)\n",
    "        print(f\"  Embarked 결측값 {df['Embarked'].isnull().sum()}개를 최빈값 '{embarked_mode}'로 대체\")\n",
    "    \n",
    "    # Fare 결측값을 중앙값으로 채우기\n",
    "    if df_processed['Fare'].isnull().sum() > 0:\n",
    "        fare_median = df_processed['Fare'].median()\n",
    "        df_processed['Fare'].fillna(fare_median, inplace=True)\n",
    "        print(f\"  Fare 결측값 {df['Fare'].isnull().sum()}개를 중앙값 {fare_median:.2f}로 대체\")\n",
    "    \n",
    "    # Cabin 결측값을 'Unknown'으로 채우기\n",
    "    if df_processed['Cabin'].isnull().sum() > 0:\n",
    "        cabin_missing = df_processed['Cabin'].isnull().sum()\n",
    "        df_processed['Cabin'].fillna('Unknown', inplace=True)\n",
    "        print(f\"  Cabin 결측값 {cabin_missing}개를 'Unknown'으로 대체\")\n",
    "    \n",
    "    # 파생 변수 생성\n",
    "    df_processed['FamilySize'] = df_processed['SibSp'] + df_processed['Parch'] + 1\n",
    "    df_processed['IsAlone'] = (df_processed['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 나이 그룹 생성\n",
    "    df_processed['AgeGroup'] = pd.cut(df_processed['Age'], \n",
    "                                    bins=[0, 18, 30, 50, 100], \n",
    "                                    labels=['Child', 'Young', 'Adult', 'Senior'])\n",
    "    \n",
    "    # 요금 그룹 생성\n",
    "    df_processed['FareGroup'] = pd.qcut(df_processed['Fare'], \n",
    "                                      q=4, \n",
    "                                      labels=['Low', 'Medium', 'High', 'VeryHigh'])\n",
    "    \n",
    "    print(f\"  파생 변수 생성 완료 (FamilySize, IsAlone, AgeGroup, FareGroup)\")\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# 결측치 행 분석 실행\n",
    "train_missing_info = analyze_missing_rows(train, \"훈련 데이터\")\n",
    "test_missing_info = analyze_missing_rows(test, \"테스트 데이터\")\n",
    "\n",
    "# 데이터 전처리 적용\n",
    "print(\"\\n데이터 전처리 실행...\")\n",
    "train_processed = preprocess_titanic_data(train, is_train=True)\n",
    "test_processed = preprocess_titanic_data(test, is_train=False)\n",
    "\n",
    "print(f\"\\n데이터 전처리가 완료되었습니다.\")\n",
    "print(f\"훈련 데이터 결측값: {train_processed.isnull().sum().sum()}\")\n",
    "print(f\"테스트 데이터 결측값: {test_processed.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LangChain 에이전트 설정 시작...\")\n",
    "\n",
    "# LangChain 에이전트 설정\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# from langchain_upstage import ChatUpstage\n",
    "\n",
    "# llm = ChatUpstage(\n",
    "#         model=\"solar-pro\",\n",
    "#         base_url=\"https://api.upstage.ai/v1\",\n",
    "#         temperature=0.5\n",
    "#     )\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo-0125', \n",
    "    temperature=0,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "# 훈련 데이터용 에이전트 생성\n",
    "train_agent = create_pandas_dataframe_agent(\n",
    "    llm,\n",
    "    train_processed,\n",
    "    agent_type=\"openai-tools\",\n",
    "    #agent_type=\"tool-calling\",\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=False,\n",
    "    allow_dangerous_code=True,\n",
    "    prefix=\"\"\"당신은 Titanic 생존 예측 데이터셋을 분석하는 전문가입니다. \n",
    "    데이터프레임의 이름은 'df'입니다. 한국어로 답변해주세요.\n",
    "    시각화를 요청받으면 matplotlib/seaborn을 사용하여 한국어 제목과 라벨로 깔끔하고 이해하기 쉬운 그래프를 만들어주세요.\n",
    "    Titanic 데이터의 특성을 고려하여 생존율, 승객 등급, 성별, 나이 등의 관점에서 분석해주세요.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"LangChain 에이전트가 성공적으로 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"기본 통계 정보 분석 시작...\")\n",
    "\n",
    "# 기본 통계 정보 확인\n",
    "response = train_agent.invoke(\"\"\"\n",
    "Titanic 데이터의 기본 통계 정보를 분석해주세요:\n",
    "1. 전체 승객 수와 생존자 수\n",
    "2. 생존율 (백분율로)\n",
    "3. 주요 수치형 변수들의 기본 통계량 (Age, Fare, FamilySize)\n",
    "4. 범주형 변수들의 분포 (Pclass, Sex, Embarked)\n",
    "\n",
    "한국어로 자세히 설명해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n기본 통계 정보 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"생존율 분포 시각화 시작...\")\n",
    "\n",
    "# 생존율 시각화\n",
    "response = train_agent.invoke(\"\"\"\n",
    "먼저 한글 폰트를 설정하세요:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "                              \n",
    "생존 여부(Survived)에 대한 다음 시각화를 생성해주세요:\n",
    "1. 생존/사망 비율을 보여주는 원형 차트 (한국어 라벨)\n",
    "2. 생존/사망 개수를 보여주는 막대 차트 (한국어 제목과 라벨)\n",
    "\n",
    "그래프는 한국어 제목과 라벨을 사용하고,\n",
    "subplot을 사용하여 한 화면에 두 차트를 배치하고, \n",
    "각 차트에 정확한 숫자와 백분율을 표시해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n생존율 분포 시각화가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상관관계 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"생존율과 변수들의 상관관계 분석 시작...\")\n",
    "\n",
    "# 생존율과 상관관계가 높은 변수들 찾기\n",
    "response = train_agent.invoke(\"\"\"\n",
    "생존 여부(Survived)와 다른 수치형 변수들 간의 상관관계를 분석해주세요:\n",
    "1. 상관계수 계산 (Age, Fare, Pclass, SibSp, Parch, FamilySize, IsAlone)\n",
    "2. 상관계수를 막대그래프로 시각화 (절댓값 기준으로 정렬)\n",
    "3. 가장 상관관계가 높은 상위 5개 변수 설명\n",
    "4. 히트맵으로 전체 상관관계 매트릭스 표시\n",
    "\n",
    "모든 그래프에 한국어 제목과 라벨을 사용해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n상관관계 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 범주형 변수 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"범주형 변수 분석 시작...\")\n",
    "\n",
    "# 성별에 따른 생존율\n",
    "response = train_agent.invoke(\"\"\"\n",
    "먼저 한글 폰트를 설정하세요:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "                                                            \n",
    "성별(Sex)에 따른 생존율을 분석하고 시각화해주세요:\n",
    "1. 성별(Sex) 생존자 수와 사망자 수를 스택형 막대그래프로 표시\n",
    "2. 성별(Sex) 생존율을 백분율로 계산하여 표시\n",
    "3. 성별(Sex)이 생존에 미치는 영향에 대한 분석\n",
    "\n",
    "한국어 제목과 라벨을 사용하고, 정확한 숫자와 백분율을 그래프에 표시해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n성별 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"승객 등급별 생존율 분석 시작...\")\n",
    "\n",
    "# 승객 등급별 생존율\n",
    "response = train_agent.invoke(\"\"\"\n",
    "승객 등급(Pclass)에 따른 생존율을 분석해주세요:\n",
    "1. 등급별 승객 수 분포 (막대그래프)\n",
    "2. 등급별 생존율 비교 (막대그래프)\n",
    "3. 등급별 평균 요금(Fare) 비교 (박스플롯)\n",
    "\n",
    "subplot을 사용하여 세 개의 그래프를 한 화면에 배치하고,\n",
    "막대별로 색상을 다르게 사용해 주세요.                              \n",
    "모든 그래프에 한국어 제목과 라벨을 사용해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n승객 등급 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"예측 모델 구축 시작...\")\n",
    "\n",
    "def build_titanic_model():\n",
    "    \"\"\"Titanic 생존 예측 모델 구축\"\"\"\n",
    "    \n",
    "    print(\"모델 구축 준비 중...\")\n",
    "    \n",
    "    # 특성 선택 (수치형 변수만 선택)\n",
    "    if 'Survived' in train_processed.columns:\n",
    "        # 범주형 변수를 수치형으로 변환\n",
    "        train_model = train_processed.copy()\n",
    "        \n",
    "        # 성별을 수치형으로 변환\n",
    "        train_model['Sex_encoded'] = (train_model['Sex'] == 'male').astype(int)\n",
    "        \n",
    "        # 승선 항구를 수치형으로 변환\n",
    "        embarked_dummies = pd.get_dummies(train_model['Embarked'], prefix='Embarked')\n",
    "        train_model = pd.concat([train_model, embarked_dummies], axis=1)\n",
    "        \n",
    "        # 연령 그룹을 수치형으로 변환\n",
    "        train_model['AgeGroup_encoded'] = train_model['AgeGroup'].cat.codes\n",
    "        \n",
    "        # 요금 그룹을 수치형으로 변환  \n",
    "        train_model['FareGroup_encoded'] = train_model['FareGroup'].cat.codes\n",
    "        \n",
    "        # 모델링에 사용할 특성 선택\n",
    "        feature_cols = ['Pclass', 'Sex_encoded', 'Age', 'SibSp', 'Parch', 'Fare', \n",
    "                       'FamilySize', 'IsAlone', 'AgeGroup_encoded', 'FareGroup_encoded']\n",
    "        \n",
    "        # 승선 항구 더미 변수 추가\n",
    "        embarked_cols = [col for col in train_model.columns if col.startswith('Embarked_')]\n",
    "        feature_cols.extend(embarked_cols)\n",
    "        \n",
    "        # 사용 가능한 특성만 선택\n",
    "        available_features = [col for col in feature_cols if col in train_model.columns]\n",
    "        \n",
    "        X = train_model[available_features]\n",
    "        y = train_model['Survived']\n",
    "        \n",
    "        print(f\"사용된 특성: {len(available_features)}개\")\n",
    "        print(f\"   - {', '.join(available_features)}\")\n",
    "        \n",
    "        # 훈련/검증 분할\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        \n",
    "        print(f\"데이터 분할 완료:\")\n",
    "        print(f\"   - 훈련 데이터: {X_train.shape[0]}개\")\n",
    "        print(f\"   - 검증 데이터: {X_val.shape[0]}개\")\n",
    "        \n",
    "        # 여러 모델 훈련\n",
    "        models = {\n",
    "            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10),\n",
    "            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "        }\n",
    "        \n",
    "        model_results = {}\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            print(f\"\\n {model_name} 모델 훈련 중...\")\n",
    "            \n",
    "            # 모델 훈련\n",
    "            if model_name == 'LogisticRegression':\n",
    "                # 로지스틱 회귀를 위한 스케일링\n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_val_scaled = scaler.transform(X_val)\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                y_pred = model.predict(X_val_scaled)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_val)\n",
    "            \n",
    "            # 성능 평가\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "            \n",
    "            model_results[model_name] = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'predictions': y_pred\n",
    "            }\n",
    "            \n",
    "            print(f\"{model_name} 정확도: {accuracy:.4f}\")\n",
    "        \n",
    "        # 최고 성능 모델 선택\n",
    "        best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['accuracy'])\n",
    "        best_model = model_results[best_model_name]['model']\n",
    "        best_accuracy = model_results[best_model_name]['accuracy']\n",
    "        \n",
    "        print(f\"\\n 최고 성능 모델: {best_model_name} (정확도: {best_accuracy:.4f})\")\n",
    "        \n",
    "        # 특성 중요도 (RandomForest인 경우)\n",
    "        if best_model_name == 'RandomForest':\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': available_features,\n",
    "                'importance': best_model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(\"\\n특성 중요도 분석:\")\n",
    "            for idx, row in feature_importance.head(10).iterrows():\n",
    "                print(f\"   {row['feature']}: {row['importance']:.4f}\")\n",
    "            \n",
    "            # 특성 중요도 시각화\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            top_features = feature_importance.head(10)\n",
    "            plt.barh(top_features['feature'], top_features['importance'])\n",
    "            plt.title('상위 10개 특성 중요도', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel('중요도')\n",
    "            plt.ylabel('특성')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # 혼동 행렬\n",
    "        cm = confusion_matrix(y_val, model_results[best_model_name]['predictions'])\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['사망', '생존'], yticklabels=['사망', '생존'])\n",
    "        plt.title(f'{best_model_name} 혼동 행렬', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('예측값')\n",
    "        plt.ylabel('실제값')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 분류 보고서\n",
    "        print(f\"\\n {best_model_name} 분류 보고서:\")\n",
    "        print(classification_report(y_val, model_results[best_model_name]['predictions'], \n",
    "                                  target_names=['사망', '생존']))\n",
    "        \n",
    "        return best_model, feature_importance if best_model_name == 'RandomForest' else None, model_results\n",
    "    \n",
    "    else:\n",
    "        print(\" Survived 컬럼이 없어서 모델을 구축할 수 없습니다.\")\n",
    "        return None, None, None\n",
    "\n",
    "# 모델 구축 실행\n",
    "model, feature_importance, model_results = build_titanic_model()\n",
    "print(\"\\n예측 모델 구축이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 종합 인사이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"종합 인사이트 생성 시작...\")\n",
    "\n",
    "# 최종 인사이트 요청\n",
    "response = train_agent.invoke(\"\"\"\n",
    "지금까지의 Titanic 데이터 분석을 바탕으로 종합적인 인사이트를 제공해주세요:\n",
    "\n",
    "1. **생존에 가장 큰 영향을 미치는 상위 5개 요인**\n",
    "   - 각 요인이 생존율에 미치는 구체적인 영향\n",
    "   - 수치적 근거와 함께 설명\n",
    "\n",
    "2. **주목할 만한 패턴이나 트렌드**\n",
    "   - 성별, 승객 등급, 연령, 가족 구성 등의 상호작용\n",
    "   - 예상과 다른 흥미로운 발견사항\n",
    "\n",
    "3. **실제 역사적 맥락에서의 해석**\n",
    "   - 1912년 사회적 배경과 분석 결과의 연관성\n",
    "   - 'Women and children first' 원칙의 데이터상 확인\n",
    "\n",
    "각 항목에 대해 구체적인 수치와 예시를 들어 한국어로 상세히 설명해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n 종합 인사이트 생성이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 분석 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"추가 분석 함수 정의 중...\")\n",
    "\n",
    "# 사용자 정의 분석 함수\n",
    "def custom_titanic_analysis(question):\n",
    "    \"\"\"사용자 정의 질문으로 Titanic 분석 수행\"\"\"\n",
    "    try:\n",
    "        print(f\" 분석 질문: {question}\")\n",
    "        response = train_agent.invoke(question)\n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        return f\" 분석 중 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "def survival_analysis_by_group(group_column):\n",
    "    \"\"\"특정 그룹별 생존율 분석\"\"\"\n",
    "    if group_column in train_processed.columns:\n",
    "        survival_by_group = train_processed.groupby(group_column)['Survived'].agg(['count', 'sum', 'mean'])\n",
    "        survival_by_group.columns = ['총 승객 수', '생존자 수', '생존율']\n",
    "        survival_by_group['생존율(%)'] = (survival_by_group['생존율'] * 100).round(1)\n",
    "        \n",
    "        print(f\"\\n {group_column}별 생존율 분석:\")\n",
    "        print(survival_by_group)\n",
    "        \n",
    "        # 시각화\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        survival_by_group['생존율(%)'].plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "        plt.title(f'{group_column}별 생존율', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel(group_column)\n",
    "        plt.ylabel('생존율 (%)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 막대 위에 값 표시\n",
    "        for i, v in enumerate(survival_by_group['생존율(%)']):\n",
    "            plt.text(i, v + 1, f'{v}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return survival_by_group\n",
    "    else:\n",
    "        print(f\" '{group_column}' 컬럼을 찾을 수 없습니다.\")\n",
    "        return None\n",
    "\n",
    "# 분석 함수들 테스트\n",
    "print(\" 추가 분석 함수들이 준비되었습니다.\")\n",
    "print(\"\\n 사용 가능한 분석 함수들:\")\n",
    "print(\"1. custom_titanic_analysis('질문') - 자유로운 분석 질문\")\n",
    "print(\"2. survival_analysis_by_group('컬럼명') - 그룹별 생존율 분석\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대화형 분석 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" 대화형 분석 예시 준비 중...\")\n",
    "\n",
    "print(\"=== 대화형 분석 예시 ===\")\n",
    "print(\"\\n 이제 자연어로 다양한 분석을 요청할 수 있습니다!\")\n",
    "print(\"\\n 분석 예시 질문들:\")\n",
    "\n",
    "example_questions = [\n",
    "    \"가장 생존율이 높은 승객 프로필은 무엇인가요?\",\n",
    "    \"나이와 성별을 동시에 고려했을 때 생존율 패턴은 어떻게 되나요?\",\n",
    "    \"1등급 승객 중에서도 사망한 사람들의 특징은 무엇인가요?\",\n",
    "    \"가족과 함께 탄 승객과 혼자 탄 승객의 생존율 차이의 원인은?\",\n",
    "    \"요금이 가장 비싼 상위 10% 승객들의 생존율은?\",\n",
    "    \"각 승선 항구별로 승객 특성과 생존율이 어떻게 다른가요?\",\n",
    "    \"어린이(18세 미만)와 노인(60세 이상)의 생존율 비교\",\n",
    "    \"객실 번호(Cabin)가 있는 승객과 없는 승객의 생존율 차이\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(example_questions, 1):\n",
    "    print(f\"{i}. {question}\")\n",
    "\n",
    "print(\"\\n 사용법:\")\n",
    "print(\"result = custom_titanic_analysis('원하는 질문')\")\n",
    "print(\"print(result)\")\n",
    "\n",
    "print(\"\\n 예시 실행:\")\n",
    "print(\"# 예: 1등급 여성 승객의 생존율 분석\")\n",
    "print(\"# result = custom_titanic_analysis('1등급 여성 승객들의 생존율과 특징을 분석해주세요')\")\n",
    "\n",
    "print(\"\\n 모든 분석이 완료되었습니다!\")\n",
    "print(\" Titanic 데이터 분석 노트북이 성공적으로 실행되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 요약 정보 출력\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TITANIC 데이터 분석 완료 요약\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if 'Survived' in train_processed.columns:\n",
    "    total_passengers = len(train_processed)\n",
    "    survivors = train_processed['Survived'].sum()\n",
    "    survival_rate = train_processed['Survived'].mean()\n",
    "    \n",
    "    print(f\" 총 승객 수: {total_passengers:,}명\")\n",
    "    print(f\" 생존자 수: {survivors:,}명\")\n",
    "    print(f\" 사망자 수: {total_passengers - survivors:,}명\")\n",
    "    print(f\" 전체 생존율: {survival_rate:.1%}\")\n",
    "\n",
    "print(f\"\\n 전처리 후 결측값:\")\n",
    "print(f\"   - 훈련 데이터: {train_processed.isnull().sum().sum()}개\")\n",
    "print(f\"   - 테스트 데이터: {test_processed.isnull().sum().sum()}개\")\n",
    "\n",
    "if 'model_results' in locals() and model_results:\n",
    "    best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['accuracy'])\n",
    "    best_accuracy = model_results[best_model_name]['accuracy']\n",
    "    print(f\"\\n 최고 성능 모델: {best_model_name}\")\n",
    "    print(f\" 예측 정확도: {best_accuracy:.1%}\")\n",
    "\n",
    "print(f\"\\n 생성된 파생 변수:\")\n",
    "derived_vars = ['FamilySize', 'IsAlone', 'AgeGroup', 'FareGroup']\n",
    "for var in derived_vars:\n",
    "    if var in train_processed.columns:\n",
    "        print(f\"  {var}\")\n",
    "\n",
    "print(\"\\n 분석이 완료되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
