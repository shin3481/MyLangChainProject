{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangGraph에서 도구(tool) 활용 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 도구(tool)를 활용한 에이전트 개발 방법을 알아봅니다\n",
    "- workflow를 직접 선언하지 않고, 사용가능한 도구들을 전달하면, 에이전트가 적합한 도구를 판단해서 사용합니다\n",
    "    - 이번 회차에서는 `ToolNode`를 통해 도구를 활용하는 방법을 알아봅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 곱합니다.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LangGraph는 `ToolNode`를 통해 도구를 활용합니다\n",
    "- `ToolNode`의 `invoke()`결과는 도구의 `invoke()` 결과와 유사합니다\n",
    "    - 도구는 도구의 실행 결과를 리턴하고, `ToolNode`는 도구의 실행 결과를 포함한 `ToolMessage`를 리턴합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_list = [add, multiply]\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "tool_node = ToolNode(tool_list)\n",
    "\n",
    "print(type(llm_with_tools))\n",
    "print(tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply.invoke({'a': 3, 'b': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = llm_with_tools.invoke('What is 3 plus 5?')\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ToolNode`를 `invoke()`하려면 `tool_calls` 속성을 포함한 `AIMessage`를 전달해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node.invoke({'messages': [ai_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 간단한 에이전트를 만들기 위해 LangGraph에서 제공하는 [`StateGraph`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"\n",
    "    에이전트 함수는 주어진 상태에서 메시지를 가져와\n",
    "    LLM과 도구를 사용하여 응답 메시지를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): 메시지 상태를 포함하는 state.\n",
    "\n",
    "    Returns:\n",
    "        MessagesState: 응답 메시지를 포함하는 새로운 state.\n",
    "    \"\"\"\n",
    "    # 상태에서 메시지를 추출합니다.\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM과 도구를 사용하여 메시지를 처리하고 응답을 생성합니다.\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # 응답 메시지를 새로운 상태로 반환합니다.\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import END\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal['tools', END]:\n",
    "    \"\"\"\n",
    "    주어진 메시지 상태를 기반으로 에이전트가 계속 진행할지 여부를 결정합니다.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): `state`를 포함하는 객체.\n",
    "\n",
    "    Returns:\n",
    "        Literal['tools', END]: 도구를 사용해야 하면 `tools`를 리턴하고, \n",
    "        답변할 준비가 되었다면 END를 반환해서 프로세스를 종료합니다.\n",
    "    \"\"\"\n",
    "    # 상태에서 메시지를 추출합니다.\n",
    "    messages = state['messages']\n",
    "    print(messages)\n",
    "    \n",
    "    # 마지막 AI 메시지를 가져옵니다.\n",
    "    last_ai_message = messages[-1]\n",
    "    \n",
    "    # 마지막 AI 메시지가 도구 호출을 포함하고 있는지 확인합니다.\n",
    "    if last_ai_message.tool_calls:\n",
    "        # 도구 호출이 있으면 'tools'를 반환합니다.\n",
    "        return 'tools'\n",
    "    \n",
    "    # 도구 호출이 없으면 END를 반환하여 프로세스를 종료합니다.\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `node`를 추가하고 `edge`로 연결합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node('agent', agent)\n",
    "graph_builder.add_node('tools', tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    ['tools', END]\n",
    ")\n",
    "graph_builder.add_edge('tools', 'agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph= graph_builder.compile()\n",
    "print(type(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "print(\"Mermaid Code:\")\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://mermaid.live/ 에서  mermain_code 로 직접 확인한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `graph.stream()`을 활용하면 에이전트가 답변을 생성하는 과정을 모니터링 할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for chunk in graph.stream({'messages': [HumanMessage('3에다 5를 더하고 거기에 8을 곱하면?')]}, stream_mode='values'):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-0lCeHk3W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
