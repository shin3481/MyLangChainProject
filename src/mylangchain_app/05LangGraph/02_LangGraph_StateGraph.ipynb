{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. StateGraph\n",
    "- 상태(state)를 기반으로 작동하는 그래프 구조\n",
    "- 실습: 레스토랑 메뉴 추천 시스템\n",
    "    - 사용자의 선호도에 따라 메뉴를 추천하고, 메뉴에 대한 정보를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) 상태(State)`\n",
    "- 상태는 그래프가 처리하는 데이터의 구조를 정의\n",
    "- 기존 상태를 override (덮어쓰기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "# 상태 Schema 정의 - 사용자의 선호도, 추천된 메뉴, 메뉴 정보를 저장\n",
    "class MenuState(TypedDict):\n",
    "    user_preference: str\n",
    "    recommended_menu: str\n",
    "    menu_info: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 노드(Node)`\n",
    "- 노드는 그래프에서 실제 작업을 수행하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_user_preference(state: MenuState) -> MenuState:\n",
    "    print(\"---랜덤 사용자 선호도 생성---\")\n",
    "    preferences = [\"육류\", \"해산물\", \"채식\", \"아무거나\"]\n",
    "    preference = random.choice(preferences)\n",
    "    print(f\"생성된 선호도: {preference}\")\n",
    "    return {\"user_preference\": preference}\n",
    "\n",
    "def recommend_menu(state: MenuState) -> MenuState:\n",
    "    print(\"---메뉴 추천---\")\n",
    "    preference = state['user_preference']\n",
    "    if preference == \"육류\":\n",
    "        menu = \"스테이크\"\n",
    "    elif preference == \"해산물\":\n",
    "        menu = \"랍스터 파스타\"\n",
    "    elif preference == \"채식\":\n",
    "        menu = \"그린 샐러드\"\n",
    "    else:\n",
    "        menu = \"오늘의 쉐프 특선\"\n",
    "    print(f\"추천 메뉴: {menu}\")\n",
    "    return {\"recommended_menu\": menu}\n",
    "\n",
    "def provide_menu_info(state: MenuState) -> MenuState:\n",
    "    print(\"---메뉴 정보 제공---\")\n",
    "    menu = state['recommended_menu']\n",
    "    if menu == \"스테이크\":\n",
    "        info = \"최상급 소고기로 만든 juicy한 스테이크입니다. 가격: 30,000원\"\n",
    "    elif menu == \"랍스터 파스타\":\n",
    "        info = \"신선한 랍스터와 al dente 파스타의 조화. 가격: 28,000원\"\n",
    "    elif menu == \"그린 샐러드\":\n",
    "        info = \"신선한 유기농 채소로 만든 건강한 샐러드. 가격: 15,000원\"\n",
    "    else:\n",
    "        info = \"쉐프가 그날그날 엄선한 특별 요리입니다. 가격: 35,000원\"\n",
    "    print(f\"메뉴 정보: {info}\")\n",
    "    return {\"menu_info\": info}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 그래프(Graph) 구성`\n",
    "- 정의한 구성 요소들을 사용하여 전체 그래프를 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 그래프 빌더 생성\n",
    "builder = StateGraph(MenuState)\n",
    "\n",
    "# 노드 추가\n",
    "builder.add_node(\"get_preference\", get_user_preference)\n",
    "builder.add_node(\"recommend\", recommend_menu)\n",
    "builder.add_node(\"provide_info\", provide_menu_info)\n",
    "\n",
    "# 엣지 추가\n",
    "builder.add_edge(START, \"get_preference\")\n",
    "builder.add_edge(\"get_preference\", \"recommend\")\n",
    "builder.add_edge(\"recommend\", \"provide_info\")\n",
    "builder.add_edge(\"provide_info\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image, display\n",
    "\n",
    "# 그래프 시각화\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "print(\"Mermaid Code:\")\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://mermaid.live/ 에서  mermain_code 로 직접 확인한다.\n",
    "\n",
    "* [Graph이미지](https://www.mermaidchart.com/play?utm_source=mermaid_live_editor&utm_medium=share#pako:eNplkEEOwiAQRa9C6qZNrFYXLmjTlUdwp6ZBOtOSIBCKJsZ4d1tqiOiKGebBf_BMuG4hoUlnmenJYV-e1Mk1zeCYHZf0WJk6dNXa1OeMUorCDm4CO3CNsYBgQXFI4zabCAtcX6-g2jRUft9YfRctNEKhTr-bbBYYuRDv6xAu2ZwdtEie1ySOLv_lPBUcysjNz74lyl9FT3xM_JCPGsMekLSA7CYdQSElXeAWC8SlFAryHkTXO7pZbaMD_vM8nmvDuHAPWkTA9MDPdRe87JAnrzcCGprA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "\n",
    "def print_result(result: MenuState):\n",
    "    print(\"\\n=== 결과 ===\")\n",
    "    print(\"선호도:\", result['user_preference'])\n",
    "    print(\"추천 메뉴:\", result['recommended_menu'])\n",
    "    print(\"메뉴 정보:\", result['menu_info'])\n",
    "    print(\"============\\n\")\n",
    "\n",
    "\n",
    "# 초기 입려\n",
    "inputs = {\"user_preference\": \"\"}\n",
    "\n",
    "# 여러 번 실행하여 테스트 \n",
    "for _ in range(2):\n",
    "    result = graph.invoke(inputs)\n",
    "    print(type(result))\n",
    "    print_result(result)\n",
    "    print(\"*\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 조건부 엣지(Edge) : RAG 적용\n",
    "- 엣지는 노드 간의 연결을 정의\n",
    "- 조건부 엣지: 사용자 입력이 메뉴 관련인지 여부에 따라 다른 경로로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) State 정의`\n",
    "- 사용자 입력이 메뉴 추천이면 벡터저장소에서 검색하여 RAG Chain을 실행하고,\n",
    "- 그렇지 않은 경우에는 LLM이 답변을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "# state 스키마 \n",
    "class MenuState(TypedDict):\n",
    "    user_query: str\n",
    "    is_menu_related: bool\n",
    "    search_results: List[str]\n",
    "    final_answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 벡터저장소 검색 도구`\n",
    "- 메뉴 검색을 위한 벡터저장소를 초기화 (기존 저장소를 로드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "# menu db 벡터 저장소 로드\n",
    "menu_db = FAISS.load_local(\n",
    "    \"../db/menu_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "print(f\" 저장된 벡터 개수: {menu_db.index.ntotal}\")\n",
    "print(f\" 벡터 차원: {menu_db.index.d}\")\n",
    "print(f\" 인덱스 타입: {type(menu_db.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 노드(Node)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    ")\n",
    "print(llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_user_query(state: MenuState) -> MenuState:\n",
    "    print('1 ==> get_user_query()')\n",
    "    #user_query = input(\"무엇을 도와드릴까요? \")\n",
    "    user_query = state['user_query']\n",
    "    return {\"user_query\": user_query}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_input(state: MenuState) -> MenuState:\n",
    "    print('2 ==> analyze_input()')\n",
    "    analyze_template = \"\"\"\n",
    "    사용자의 입력을 분석하여 레스토랑 메뉴 추천이나 음식 정보에 관한 질문인지 판단하세요.\n",
    "\n",
    "    사용자 입력: {user_query}\n",
    "\n",
    "    레스토랑 메뉴나 음식 정보에 관한 질문이면 \"True\", 아니면 \"False\"로 답변하세요.\n",
    "\n",
    "    답변:\n",
    "    \"\"\"\n",
    "    analyze_prompt = ChatPromptTemplate.from_template(analyze_template)\n",
    "    analyze_chain = analyze_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    result = analyze_chain.invoke({\"user_query\": state['user_query']})\n",
    "    print('====> result.strip().lower()', result.strip().lower())\n",
    "    is_menu_related = result.strip().lower() == \"true\"\n",
    "    \n",
    "    return {\"is_menu_related\": is_menu_related}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'search_menu_info' 함수는 벡터 데이터베이스에서 관련 메뉴 정보를 검색합니다.\n",
    "def search_menu_info(state: MenuState) -> MenuState:\n",
    "    print('3 ==> search_menu_info()')\n",
    "    \n",
    "    # 'menu_db'에서 사용자 질의와 유사한 문서 2개를 검색합니다.\n",
    "    results = menu_db.similarity_search(state['user_query'], k=2)\n",
    "    \n",
    "    # 검색된 문서들의 내용만 추출하여 리스트로 만듭니다.\n",
    "    search_results = [doc.page_content for doc in results]\n",
    "    \n",
    "    # 검색 결과를 상태에 저장하여 다음 단계에 전달합니다.\n",
    "    return {\"search_results\": search_results}\n",
    "\n",
    "# 'generate_menu_response' 함수는 검색된 메뉴 정보를 활용하여 답변을 생성합니다.\n",
    "def generate_menu_response(state: MenuState) -> MenuState:\n",
    "    print('4 ==> generate_menu_response()')\n",
    "    \n",
    "    # 답변 생성에 사용될 프롬프트 템플릿을 정의합니다.\n",
    "    response_template = \"\"\"\n",
    "    사용자 입력: {user_query}\n",
    "    메뉴 관련 검색 결과: {search_results}\n",
    "\n",
    "    위 정보를 바탕으로 사용자의 메뉴 관련 질문에 대한 상세한 답변을 생성하세요. \n",
    "    검색 결과의 정보를 활용하여 정확하고 유용한 정보를 제공하세요.\n",
    "\n",
    "    답변:\n",
    "    \"\"\"\n",
    "    \n",
    "    # 템플릿을 기반으로 프롬프트 체인을 구성합니다.\n",
    "    # 'response_prompt'가 LLM에 입력되고, 결과는 문자열로 파싱됩니다.\n",
    "    response_prompt = ChatPromptTemplate.from_template(response_template)\n",
    "    response_chain = response_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    # 구성된 체인을 실행하여 최종 답변을 얻습니다.\n",
    "    final_answer = response_chain.invoke({\"user_query\": state['user_query'], \"search_results\": state['search_results']})\n",
    "    print(f\"\\n메뉴 어시스턴트: {final_answer}\")\n",
    "    \n",
    "    # 생성된 답변을 상태에 저장합니다.\n",
    "    return {\"final_answer\": final_answer}\n",
    "\n",
    "# 'generate_general_response' 함수는 메뉴와 관련 없는 일반적인 질문에 응답합니다.\n",
    "def generate_general_response(state: MenuState) -> MenuState:\n",
    "    print('5 ==> generate_general_response()')\n",
    "    \n",
    "    # 일반적인 대화에 사용될 프롬프트 템플릿을 정의합니다.\n",
    "    response_template = \"\"\"\n",
    "    사용자 입력: {user_query}\n",
    "\n",
    "    위 입력은 레스토랑 메뉴나 음식과 관련이 없습니다. \n",
    "    일반적인 대화 맥락에서 적절한 답변을 생성하세요.\n",
    "\n",
    "    답변:\n",
    "    \"\"\"\n",
    "    \n",
    "    # 템플릿을 기반으로 프롬프트 체인을 구성합니다.\n",
    "    response_prompt = ChatPromptTemplate.from_template(response_template)\n",
    "    response_chain = response_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    # 체인을 실행하여 일반적인 답변을 생성합니다.\n",
    "    final_answer = response_chain.invoke({\"user_query\": state['user_query']})\n",
    "    print(f\"\\n일반 어시스턴트: {final_answer}\")\n",
    "    \n",
    "    # 생성된 답변을 상태에 저장합니다.\n",
    "    return {\"final_answer\": final_answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 엣지(Edge)`\n",
    "* routing(분기)를 처리하는 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def decide_next_step(state: MenuState) -> Literal[\"search_menu_info\", \"generate_general_response\"]:\n",
    "    # 현재 상태에서 'is_menu_related' 값을 출력하여 다음 결정 과정을 로그로 남깁니다.\n",
    "    print('6 Edge ==> decide_next_step() is_menu_related = ', state['is_menu_related'])\n",
    "    \n",
    "    # 만약 'is_menu_related'가 True이면 (질문이 메뉴 관련 질문일 때),\n",
    "    # 메뉴 정보를 검색하는 노드로 이동하도록 \"search_menu_info\"를 반환합니다.\n",
    "    if state['is_menu_related']:\n",
    "        return \"search_menu_info\"\n",
    "    \n",
    "    # 그렇지 않다면 (질문이 일반적인 질문일 때),\n",
    "    # 일반적인 답변을 생성하는 노드로 이동하도록 \"generate_general_response\"를 반환합니다.\n",
    "    else:\n",
    "        return \"generate_general_response\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) 그래프(Graph) 구성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# StateGraph 클래스를 사용하여 그래프를 구성합니다. \n",
    "# MenuState는 그래프가 공유하는 상태(state)의 스키마를 정의합니다.\n",
    "builder = StateGraph(MenuState)\n",
    "\n",
    "# --- 노드 추가 ---\n",
    "# 각 노드는 그래프의 한 단계를 나타내며, 특정 작업을 수행합니다.\n",
    "# \"get_user_query\": 사용자의 입력(질문)을 가져오는 노드\n",
    "# MenuState 객체의 user_query 변수에 값을 저장하는 노드\n",
    "builder.add_node(\"get_user_query\", get_user_query)\n",
    "\n",
    "# \"analyze_input\": 사용자 질의가 메뉴와 관련 있는지 분석하는 노드\n",
    "# MenuState 객체의 is_menu_related 변수에 값을 저장하는 노드\n",
    "builder.add_node(\"analyze_input\", analyze_input)\n",
    "\n",
    "# \"search_menu_info\": 메뉴 관련 질의일 경우, 벡터DB에서 정보를 검색하는 노드\n",
    "# MenuState 객체의 search_results 변수에 값을 저장하는 노드\n",
    "builder.add_node(\"search_menu_info\", search_menu_info)\n",
    "\n",
    "# \"generate_menu_response\": 검색된 메뉴 정보를 바탕으로 답변을 생성하는 노드\n",
    "# MenuState 객체의 final_answer 변수에 값을 저장하는 노드\n",
    "builder.add_node(\"generate_menu_response\", generate_menu_response)\n",
    "\n",
    "# \"generate_general_response\": 메뉴와 관련 없는 일반적인 질문에 답변하는 노드\n",
    "# MenuState 객체의 final_answer 변수에 값을 저장하는 노드\n",
    "builder.add_node(\"generate_general_response\", generate_general_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 엣지(연결) 추가 ---\n",
    "# 그래프의 시작점을 정의하고, 노드들을 순서대로 연결합니다.\n",
    "# START에서 \"get_user_query\" 노드로 시작합니다.\n",
    "builder.add_edge(START, \"get_user_query\")\n",
    "\n",
    "# \"get_user_query\" 노드에서 \"analyze_input\" 노드로 이동합니다.\n",
    "builder.add_edge(\"get_user_query\", \"analyze_input\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 조건부 엣지 추가 ---\n",
    "# \"analyze_input\" 노드의 결과에 따라 동적으로 다음 노드를 결정합니다.\n",
    "# decide_next_step 함수가 반환하는 값에 따라 흐름이 분기됩니다.\n",
    "builder.add_conditional_edges(\n",
    "    \"analyze_input\",            # 현재 노드: \"analyze_input\"\n",
    "    decide_next_step,           # 라우팅 함수: 'decide_next_step'\n",
    "    {\n",
    "        # 'decide_next_step'이 \"search_menu_info\"를 반환하면, 해당 노드로 이동\n",
    "        \"search_menu_info\": \"search_menu_info\",\n",
    "        # 'decide_next_step'이 \"generate_general_response\"를 반환하면, 해당 노드로 이동\n",
    "        \"generate_general_response\": \"generate_general_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# --- 최종 엣지 ---\n",
    "# 분기된 흐름이 최종 답변을 생성하고 종료되도록 연결합니다.\n",
    "# \"search_menu_info\" 노드는 \"generate_menu_response\" 노드로 이어집니다.\n",
    "builder.add_edge(\"search_menu_info\", \"generate_menu_response\")\n",
    "\n",
    "# 메뉴 관련 답변 생성 후 그래프를 종료합니다.\n",
    "builder.add_edge(\"generate_menu_response\", END)\n",
    "\n",
    "# 일반적인 답변 생성 후 그래프를 종료합니다.\n",
    "builder.add_edge(\"generate_general_response\", END)\n",
    "\n",
    "# --- 그래프 컴파일 ---\n",
    "# 정의된 노드와 엣지를 기반으로 실행 가능한 그래프를 최적화합니다.\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image, display\n",
    "\n",
    "# 그래프 시각화\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "print(\"Mermaid Code:\")\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Graph이미지](https://mermaidchart.com/play?utm_source=mermaid_live_editor&utm_medium=share#pako:eNp9U12vojAQ_Stk9gUT8GJRwWJ8uf6EfdplQypMhQQKt7TJqvG_by0uCX7cp85Mz5npOW0vkLcFAoWjZF3p_NwnqUhVlvWKSbO4v7fdbsy2H93uz4xSyivZqxvwiCrTPcrsS6M8udN0dkMwwerTGbNKdFq5k8zu98hkXmYNCm2qvHUfC7NhjkDJFA5liX3Xih7d1-UpYwjqF6THndkgHUUxCrfxKLtmg-rREMf3d85UdPIk2vHnFvVm6jvCow_Js992_ISavLL0fspXViXfWmWJdxOS99fwBMuNUf0euVMgZ7pWDq_qmv7ghAece3Ul0C-xOpaKLuZkQrAPy8L9tmN5pU40mABuV3Bvd-CHNc_BM0-3KoByVvfoQYOyYbccLqlwnBRUiQ2mQE14P04KqbgaXsfEr7ZtgCqpDVO2-lj-T3RXGJ37ipl_0YzNpdGI8rPVQgEly43tAfQCf4FGRksUBmQVbtaLcLlZeXACuljG83hN4g1ZxeEyIvHVg7MdGsyjKCQRIYt1SIIgjKLrP64fR1Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(6) Graph 실행`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"레스토랑의 메뉴를 추천해 주세요\"\n",
    "initial_state = {'user_query':query}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"레스토랑의 해산물 메뉴를 추천해 주세요\"\n",
    "initial_state = {'user_query':query}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"안녕하세요? 내일 날씨는 어떤가요?\"\n",
    "initial_state = {'user_query':query}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     initial_state = {'user_query':''}\n",
    "#     graph.invoke(initial_state) \n",
    "#     continue_chat = input(\"다른 질문이 있으신가요? (y/n): \").lower()\n",
    "#     if continue_chat != 'y':\n",
    "#         print(\"대화를 종료합니다. 감사합니다!\")\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
